{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9v8gUwbokZ6X"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A4w_JfITkbSv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4c7348-118f-46d4-db01-d69642c04f5a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Cm-cWva8jrHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "2gYpxQ2gnkdg"
      },
      "outputs": [],
      "source": [
        "!mkdir ~/.kaggle\n",
        "\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ux6ONJbXnlHD",
        "outputId": "8f2cdb6e-ae03-46e3-b0f2-a7bafdb288dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading isic-2024-challenge.zip to /content\n",
            "100% 2.00G/2.00G [00:16<00:00, 92.9MB/s]\n",
            "100% 2.00G/2.00G [00:16<00:00, 128MB/s] \n"
          ]
        }
      ],
      "source": [
        "\n",
        "!kaggle competitions download -c isic-2024-challenge\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IP6xCDVenyMn",
        "outputId": "b74f088c-eb39-4401-83f6-4d2ca6dd3204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting timm\n",
            "  Downloading timm-1.0.9-py3-none-any.whl.metadata (42 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/42.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/42.4 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from timm) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from timm) (0.19.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from timm) (6.0.2)\n",
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.10/dist-packages (from timm) (0.24.7)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.10/dist-packages (from timm) (0.4.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (3.16.1)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2024.6.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (24.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub->timm) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->timm) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->timm) (3.1.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision->timm) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->timm) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface_hub->timm) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->timm) (1.3.0)\n",
            "Downloading timm-1.0.9-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: timm\n",
            "Successfully installed timm-1.0.9\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade timm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zY_YcH7Nn0wo",
        "outputId": "68d11fa7-54a6-4193-ca3b-ce388575a475"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydicom\n",
            "  Downloading pydicom-3.0.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-2.14.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (71.0.4)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading pydicom-3.0.1-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.18.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.7/9.7 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.14.0-py2.py3-none-any.whl (311 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.4/311.4 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: smmap, setproctitle, sentry-sdk, pydicom, docker-pycreds, gitdb, gitpython, wandb\n",
            "Successfully installed docker-pycreds-0.4.0 gitdb-4.0.11 gitpython-3.1.43 pydicom-3.0.1 sentry-sdk-2.14.0 setproctitle-1.3.3 smmap-5.0.1 wandb-0.18.1\n"
          ]
        }
      ],
      "source": [
        "!pip install pydicom wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-cFkQ4A0G5Ya",
        "outputId": "c06941fe-4530-4fea-992f-06c5a948805a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting libauc\n",
            "  Downloading libauc-1.4.0-py3-none-any.whl.metadata (8.1 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from libauc) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from libauc) (0.19.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from libauc) (1.26.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from libauc) (4.66.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from libauc) (1.13.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from libauc) (2.1.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from libauc) (10.4.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from libauc) (1.3.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (from libauc) (4.10.0.84)\n",
            "Collecting torch-geometric (from libauc)\n",
            "  Downloading torch_geometric-2.6.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/63.1 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ogb (from libauc)\n",
            "  Downloading ogb-1.3.6-py3-none-any.whl.metadata (6.2 kB)\n",
            "Collecting webdataset (from libauc)\n",
            "  Downloading webdataset-0.2.100-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from ogb->libauc) (1.16.0)\n",
            "Requirement already satisfied: urllib3>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from ogb->libauc) (2.0.7)\n",
            "Collecting outdated>=0.2.0 (from ogb->libauc)\n",
            "  Downloading outdated-0.2.2-py2.py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->libauc) (2024.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->libauc) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->libauc) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->libauc) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->libauc) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->libauc) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->libauc) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->libauc) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from torch-geometric->libauc) (3.10.5)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric->libauc) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric->libauc) (3.1.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric->libauc) (2.32.3)\n",
            "Collecting braceexpand (from webdataset->libauc)\n",
            "  Downloading braceexpand-0.1.7-py2.py3-none-any.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from webdataset->libauc) (6.0.2)\n",
            "Requirement already satisfied: setuptools>=44 in /usr/local/lib/python3.10/dist-packages (from outdated>=0.2.0->ogb->libauc) (71.0.4)\n",
            "Collecting littleutils (from outdated>=0.2.0->ogb->libauc)\n",
            "  Downloading littleutils-0.2.4-py3-none-any.whl.metadata (679 bytes)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->libauc) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->libauc) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->libauc) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->libauc) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->libauc) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->libauc) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->torch-geometric->libauc) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->libauc) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->libauc) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->libauc) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric->libauc) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->libauc) (1.3.0)\n",
            "Downloading libauc-1.4.0-py3-none-any.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.8/130.8 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ogb-1.3.6-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.8/78.8 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch_geometric-2.6.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m27.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading webdataset-0.2.100-py3-none-any.whl (74 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.8/74.8 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading outdated-0.2.2-py2.py3-none-any.whl (7.5 kB)\n",
            "Downloading braceexpand-0.1.7-py2.py3-none-any.whl (5.9 kB)\n",
            "Downloading littleutils-0.2.4-py3-none-any.whl (8.1 kB)\n",
            "Installing collected packages: braceexpand, webdataset, littleutils, outdated, ogb, torch-geometric, libauc\n",
            "Successfully installed braceexpand-0.1.7 libauc-1.4.0 littleutils-0.2.4 ogb-1.3.6 outdated-0.2.2 torch-geometric-2.6.0 webdataset-0.2.100\n"
          ]
        }
      ],
      "source": [
        "!pip install -U libauc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "bDcPuJ56n3Ld"
      },
      "outputs": [],
      "source": [
        "!unzip -q /content/isic-2024-challenge.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "bDZu-Zxin8ot"
      },
      "outputs": [],
      "source": [
        "# !kaggle datasets download -d fabiangrger/isic-2024-challenge-selfclean-scores\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "CWnTSmxaWiR-"
      },
      "outputs": [],
      "source": [
        "# !unzip -q /content/isic-2024-challenge-selfclean-scores.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5kY8819bVBfY"
      },
      "source": [
        "# Train an ImageNet to classify the ISIC 2024 Data / Generate OOF Preds\n",
        "* This is a (detuned) public version of my notebook intended to demonstrate how to generate OOF preds for use by LGBM\n",
        "* Idea is to show how this works (it will probably not produce a rocking LB score)\n",
        "* This notebook will predicts on test using an average of all folds\n",
        "* It will also output the models / oof_predictions.csv for easy integration with LGBM / similar...\n",
        "\n",
        "* For an example of how to use see https://www.kaggle.com/code/richolson/isic-2024-borrowed-179lb-tabular-oof-imagenet/notebook\n",
        "\n",
        "* Note: There is a bunch of redundant code here (intent is to make sharing with other notebooks easier)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qTsQHR8MVBfZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f259c4e2-6c4c-4f2a-c9ea-3bb068dbffcc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/albumentations/__init__.py:13: UserWarning: A new version of Albumentations is available: 1.4.16 (you have 1.4.15). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
            "  check_for_updates()\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from datetime import datetime\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "import polars as pl\n",
        "from libauc.sampler import DualSampler\n",
        "from libauc.losses import pAUCLoss\n",
        "from libauc.optimizers import SOPAs, SOPA\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import io\n",
        "import h5py\n",
        "import math\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "from torchvision import transforms\n",
        "import timm\n",
        "\n",
        "from sklearn.metrics import hamming_loss, f1_score, roc_curve, auc, classification_report\n",
        "from sklearn.preprocessing import binarize\n",
        "from sklearn.model_selection import GroupShuffleSplit\n",
        "\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "from sklearn.model_selection import GroupKFold, StratifiedGroupKFold"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsIuW63fVBfZ"
      },
      "source": [
        "# Misc. Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zwj7sIJbVBfZ",
        "outputId": "65c23420-48af-416d-d23e-0c4d50825f1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "GPU: Tesla T4\n",
            "Number of GPUs: 1\n"
          ]
        }
      ],
      "source": [
        "# Set up device and random seed\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "\n",
        "random_seed = 42\n",
        "random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "\n",
        "#number of epochs to train for\n",
        "num_epochs = 50\n",
        "\n",
        "#train entire model vs. just the classifier\n",
        "freeze_base_model = False  #didn't get good results\n",
        "\n",
        "# if this is set to true - full model is only generated as part of scoring (quick_train_record_count used)\n",
        "# this saves GPU quota - but saved model won't reflect what was scored...\n",
        "full_train_only_when_scoring = False  #must be False to save full model!\n",
        "quick_train_record_count = 50000   #need to get at least some positive cases even for test run"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6quiUklcVBfa"
      },
      "source": [
        "# Load meta - and split folds\n",
        "* Maintain consistency with tabular data in other notebooks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fz8sxdO6VBfa"
      },
      "outputs": [],
      "source": [
        "bad_ids = ['ISIC_0091661', 'ISIC_0157300', 'ISIC_0164004', 'ISIC_0225902',\n",
        "       'ISIC_0247991', 'ISIC_0253221', 'ISIC_0275821', 'ISIC_0276162',\n",
        "       'ISIC_0321282', 'ISIC_0512487', 'ISIC_0573025', 'ISIC_0749379',\n",
        "       'ISIC_0887823', 'ISIC_1142893', 'ISIC_1180656', 'ISIC_1194950',\n",
        "       'ISIC_1280179', 'ISIC_1334224', 'ISIC_1338006', 'ISIC_1443812',\n",
        "       'ISIC_1488609', 'ISIC_1618438', 'ISIC_1716141', 'ISIC_1755348',\n",
        "       'ISIC_1882290', 'ISIC_2066646', 'ISIC_2082383', 'ISIC_2153489',\n",
        "       'ISIC_2185868', 'ISIC_2301755', 'ISIC_2325643', 'ISIC_2326801',\n",
        "       'ISIC_2501464', 'ISIC_2563846', 'ISIC_2592061', 'ISIC_2649560',\n",
        "       'ISIC_2842612', 'ISIC_3019770', 'ISIC_3245832', 'ISIC_3355799',\n",
        "       'ISIC_3606755', 'ISIC_3673016', 'ISIC_3856578', 'ISIC_3902330',\n",
        "       'ISIC_3905526', 'ISIC_3915836', 'ISIC_3970343', 'ISIC_4029206',\n",
        "       'ISIC_4172573', 'ISIC_4244859', 'ISIC_4435163', 'ISIC_4590578',\n",
        "       'ISIC_4628194', 'ISIC_4723477', 'ISIC_4794318', 'ISIC_4837618',\n",
        "       'ISIC_4859161', 'ISIC_4884516', 'ISIC_4992507', 'ISIC_5129222',\n",
        "       'ISIC_5374420', 'ISIC_5446672', 'ISIC_5644802', 'ISIC_5678455',\n",
        "       'ISIC_5687461', 'ISIC_5873888', 'ISIC_5874842', 'ISIC_5938732',\n",
        "       'ISIC_5990814', 'ISIC_6021059', 'ISIC_6145237', 'ISIC_6233830',\n",
        "       'ISIC_6265900', 'ISIC_6290217', 'ISIC_6303557', 'ISIC_6347423',\n",
        "       'ISIC_6415548', 'ISIC_6443962', 'ISIC_6505439', 'ISIC_6731439',\n",
        "       'ISIC_6757661', 'ISIC_6794549', 'ISIC_6796625', 'ISIC_6838918',\n",
        "       'ISIC_6931102', 'ISIC_7028157', 'ISIC_7348810', 'ISIC_7358578',\n",
        "       'ISIC_7386083', 'ISIC_7445245', 'ISIC_7478620', 'ISIC_7546705',\n",
        "       'ISIC_7805616', 'ISIC_8091604', 'ISIC_8182531', 'ISIC_8278020',\n",
        "       'ISIC_8379868', 'ISIC_8537711', 'ISIC_8644028', 'ISIC_8653720',\n",
        "       'ISIC_8755758', 'ISIC_9118564', 'ISIC_9156598', 'ISIC_9342841',\n",
        "       'ISIC_9458222', 'ISIC_9476302', 'ISIC_9546926', 'ISIC_9611761',\n",
        "       'ISIC_9645582', 'ISIC_9675639', 'ISIC_9713969', 'ISIC_9758190',\n",
        "        'ISIC_0235999', 'ISIC_0633292', 'ISIC_1137305', 'ISIC_1203239',\n",
        "       'ISIC_1243149', 'ISIC_1449578', 'ISIC_1642217', 'ISIC_1939971',\n",
        "       'ISIC_1992066', 'ISIC_1997122', 'ISIC_3113900', 'ISIC_3809050',\n",
        "       'ISIC_3939743', 'ISIC_4368177', 'ISIC_4704252', 'ISIC_4711591',\n",
        "       'ISIC_5063101', 'ISIC_5105473', 'ISIC_5290013', 'ISIC_5859200',\n",
        "       'ISIC_6050068', 'ISIC_7083114', 'ISIC_7134832', 'ISIC_7210490',\n",
        "       'ISIC_8397035', 'ISIC_8644948', 'ISIC_8829281', 'ISIC_8897434',\n",
        "       'ISIC_9183347', 'ISIC_9200535', 'ISIC_9441116', 'ISIC_9500444']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w28NFi-qNuG0",
        "outputId": "3a579a6c-6546-4b61-ce51-33aee8abeec2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "...83 FEATURES IN TOTAL...\n",
            "\t– num_cols: 34\n",
            "\t– new_num_cols: 42\n",
            "\t– cat_cols: 6\n",
            "\t– norm_cols: 76\n",
            "\t– special_cols: 1\n"
          ]
        }
      ],
      "source": [
        "num_cols = [\n",
        "    'age_approx',                        # Approximate age of patient at time of imaging.\n",
        "    'clin_size_long_diam_mm',            # Maximum diameter of the lesion (mm).+\n",
        "    'tbp_lv_A',                          # A inside  lesion.+\n",
        "    'tbp_lv_Aext',                       # A outside lesion.+\n",
        "    'tbp_lv_B',                          # B inside  lesion.+\n",
        "    'tbp_lv_Bext',                       # B outside lesion.+\n",
        "    'tbp_lv_C',                          # Chroma inside  lesion.+\n",
        "    'tbp_lv_Cext',                       # Chroma outside lesion.+\n",
        "    'tbp_lv_H',                          # Hue inside the lesion; calculated as the angle of A* and B* in LAB* color space. Typical values range from 25 (red) to 75 (brown).+\n",
        "    'tbp_lv_Hext',                       # Hue outside lesion.+\n",
        "    'tbp_lv_L',                          # L inside lesion.+\n",
        "    'tbp_lv_Lext',                       # L outside lesion.+\n",
        "    'tbp_lv_areaMM2',                    # Area of lesion (mm^2).+\n",
        "    'tbp_lv_area_perim_ratio',           # Border jaggedness, the ratio between lesions perimeter and area. Circular lesions will have low values; irregular shaped lesions will have higher values. Values range 0-10.+\n",
        "    'tbp_lv_color_std_mean',             # Color irregularity, calculated as the variance of colors within the lesion's boundary.\n",
        "    'tbp_lv_deltaA',                     # Average A contrast (inside vs. outside lesion).+\n",
        "    'tbp_lv_deltaB',                     # Average B contrast (inside vs. outside lesion).+\n",
        "    'tbp_lv_deltaL',                     # Average L contrast (inside vs. outside lesion).+\n",
        "    'tbp_lv_deltaLB',                    #\n",
        "    'tbp_lv_deltaLBnorm',                # Contrast between the lesion and its immediate surrounding skin. Low contrast lesions tend to be faintly visible such as freckles; high contrast lesions tend to be those with darker pigment. Calculated as the average delta LB of the lesion relative to its immediate background in LAB* color space. Typical values range from 5.5 to 25.+\n",
        "    'tbp_lv_eccentricity',               # Eccentricity.+\n",
        "    'tbp_lv_minorAxisMM',                # Smallest lesion diameter (mm).+\n",
        "    'tbp_lv_nevi_confidence',            # Nevus confidence score (0-100 scale) is a convolutional neural network classifier estimated probability that the lesion is a nevus. The neural network was trained on approximately 57,000 lesions that were classified and labeled by a dermatologist.+,++\n",
        "    'tbp_lv_norm_border',                # Border irregularity (0-10 scale); the normalized average of border jaggedness and asymmetry.+\n",
        "    'tbp_lv_norm_color',                 # Color variation (0-10 scale); the normalized average of color asymmetry and color irregularity.+\n",
        "    'tbp_lv_perimeterMM',                # Perimeter of lesion (mm).+\n",
        "    'tbp_lv_radial_color_std_max',       # Color asymmetry, a measure of asymmetry of the spatial distribution of color within the lesion. This score is calculated by looking at the average standard deviation in LAB* color space within concentric rings originating from the lesion center. Values range 0-10.+\n",
        "    'tbp_lv_stdL',                       # Standard deviation of L inside  lesion.+\n",
        "    'tbp_lv_stdLExt',                    # Standard deviation of L outside lesion.+\n",
        "    'tbp_lv_symm_2axis',                 # Border asymmetry; a measure of asymmetry of the lesion's contour about an axis perpendicular to the lesion's most symmetric axis. Lesions with two axes of symmetry will therefore have low scores (more symmetric), while lesions with only one or zero axes of symmetry will have higher scores (less symmetric). This score is calculated by comparing opposite halves of the lesion contour over many degrees of rotation. The angle where the halves are most similar identifies the principal axis of symmetry, while the second axis of symmetry is perpendicular to the principal axis. Border asymmetry is reported as the asymmetry value about this second axis. Values range 0-10.+\n",
        "    'tbp_lv_symm_2axis_angle',           # Lesion border asymmetry angle.+\n",
        "    'tbp_lv_x',                          # X-coordinate of the lesion on 3D TBP.+\n",
        "    'tbp_lv_y',                          # Y-coordinate of the lesion on 3D TBP.+\n",
        "    'tbp_lv_z',                          # Z-coordinate of the lesion on 3D TBP.+\n",
        "]\n",
        "\n",
        "new_num_cols = [\n",
        "    'lesion_size_ratio',                 # tbp_lv_minorAxisMM      / clin_size_long_diam_mm\n",
        "    'lesion_shape_index',                # tbp_lv_areaMM2          / tbp_lv_perimeterMM **2\n",
        "    'hue_contrast',                      # tbp_lv_H                - tbp_lv_Hext              abs\n",
        "    'luminance_contrast',                # tbp_lv_L                - tbp_lv_Lext              abs\n",
        "    'lesion_color_difference',           # tbp_lv_deltaA **2       + tbp_lv_deltaB **2 + tbp_lv_deltaL **2  sqrt\n",
        "    'border_complexity',                 # tbp_lv_norm_border      + tbp_lv_symm_2axis\n",
        "    'color_uniformity',                  # tbp_lv_color_std_mean   / tbp_lv_radial_color_std_max\n",
        "\n",
        "    'position_distance_3d',              # tbp_lv_x **2 + tbp_lv_y **2 + tbp_lv_z **2  sqrt\n",
        "    'perimeter_to_area_ratio',           # tbp_lv_perimeterMM      / tbp_lv_areaMM2\n",
        "    'area_to_perimeter_ratio',           # tbp_lv_areaMM2          / tbp_lv_perimeterMM\n",
        "    'lesion_visibility_score',           # tbp_lv_deltaLBnorm      + tbp_lv_norm_color\n",
        "    'symmetry_border_consistency',       # tbp_lv_symm_2axis       * tbp_lv_norm_border\n",
        "    'consistency_symmetry_border',       # tbp_lv_symm_2axis       * tbp_lv_norm_border / (tbp_lv_symm_2axis + tbp_lv_norm_border)\n",
        "\n",
        "    'color_consistency',                 # tbp_lv_stdL             / tbp_lv_Lext\n",
        "    'consistency_color',                 # tbp_lv_stdL*tbp_lv_Lext / tbp_lv_stdL + tbp_lv_Lext\n",
        "    'size_age_interaction',              # clin_size_long_diam_mm  * age_approx\n",
        "    'hue_color_std_interaction',         # tbp_lv_H                * tbp_lv_color_std_mean\n",
        "    'lesion_severity_index',             # tbp_lv_norm_border      + tbp_lv_norm_color + tbp_lv_eccentricity / 3\n",
        "    'shape_complexity_index',            # border_complexity       + lesion_shape_index\n",
        "    'color_contrast_index',              # tbp_lv_deltaA + tbp_lv_deltaB + tbp_lv_deltaL + tbp_lv_deltaLBnorm\n",
        "\n",
        "    'log_lesion_area',                   # tbp_lv_areaMM2          + 1  np.log\n",
        "    'normalized_lesion_size',            # clin_size_long_diam_mm  / age_approx\n",
        "    'mean_hue_difference',               # tbp_lv_H                + tbp_lv_Hext    / 2\n",
        "    'std_dev_contrast',                  # tbp_lv_deltaA **2 + tbp_lv_deltaB **2 + tbp_lv_deltaL **2   / 3  np.sqrt\n",
        "    'color_shape_composite_index',       # tbp_lv_color_std_mean   + bp_lv_area_perim_ratio + tbp_lv_symm_2axis   / 3\n",
        "    'lesion_orientation_3d',             # tbp_lv_y                , tbp_lv_x  np.arctan2\n",
        "    'overall_color_difference',          # tbp_lv_deltaA           + tbp_lv_deltaB + tbp_lv_deltaL   / 3\n",
        "\n",
        "    'symmetry_perimeter_interaction',    # tbp_lv_symm_2axis       * tbp_lv_perimeterMM\n",
        "    'comprehensive_lesion_index',        # tbp_lv_area_perim_ratio + tbp_lv_eccentricity + bp_lv_norm_color + tbp_lv_symm_2axis   / 4\n",
        "    'color_variance_ratio',              # tbp_lv_color_std_mean   / tbp_lv_stdLExt\n",
        "    'border_color_interaction',          # tbp_lv_norm_border      * tbp_lv_norm_color\n",
        "    'border_color_interaction_2',\n",
        "    'size_color_contrast_ratio',         # clin_size_long_diam_mm  / tbp_lv_deltaLBnorm\n",
        "    'age_normalized_nevi_confidence',    # tbp_lv_nevi_confidence  / age_approx\n",
        "    'age_normalized_nevi_confidence_2',\n",
        "    'color_asymmetry_index',             # tbp_lv_symm_2axis       * tbp_lv_radial_color_std_max\n",
        "\n",
        "    'volume_approximation_3d',           # tbp_lv_areaMM2          * sqrt(tbp_lv_x**2 + tbp_lv_y**2 + tbp_lv_z**2)\n",
        "    'color_range',                       # abs(tbp_lv_L - tbp_lv_Lext) + abs(tbp_lv_A - tbp_lv_Aext) + abs(tbp_lv_B - tbp_lv_Bext)\n",
        "    'shape_color_consistency',           # tbp_lv_eccentricity     * tbp_lv_color_std_mean\n",
        "    'border_length_ratio',               # tbp_lv_perimeterMM      / pi * sqrt(tbp_lv_areaMM2 / pi)\n",
        "    'age_size_symmetry_index',           # age_approx              * clin_size_long_diam_mm * tbp_lv_symm_2axis\n",
        "    'index_age_size_symmetry',           # age_approx              * tbp_lv_areaMM2 * tbp_lv_symm_2axis\n",
        "]\n",
        "\n",
        "cat_cols = ['sex', 'anatom_site_general', 'tbp_tile_type', 'tbp_lv_location', 'tbp_lv_location_simple', 'attribution']\n",
        "norm_cols = [f'{col}_patient_norm' for col in num_cols + new_num_cols]\n",
        "special_cols = ['count_per_patient']\n",
        "\n",
        "#norm_cols += image_cols\n",
        "feature_cols = num_cols + cat_cols + special_cols + new_num_cols # norm_cols\n",
        "\n",
        "print(f\"...{len(feature_cols)} FEATURES IN TOTAL...\")\n",
        "print(f\"\\t– num_cols: {len(num_cols)}\");\n",
        "print(f\"\\t– new_num_cols: {len(new_num_cols)}\");\n",
        "print(f\"\\t– cat_cols: {len(cat_cols)}\");\n",
        "print(f\"\\t– norm_cols: {len(norm_cols)}\");\n",
        "print(f\"\\t– special_cols: {len(special_cols)}\");"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "_4PcE6-yNxHq"
      },
      "outputs": [],
      "source": [
        "\n",
        "def read_data(path):\n",
        "    return (\n",
        "        pl.read_csv(path)\n",
        "        .with_columns(\n",
        "            pl.col('age_approx').cast(pl.Utf8).replace('NA', np.nan).cast(pl.Float64),\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col(pl.Float64).fill_nan(pl.col(pl.Float64).median()), # You may want to impute test data with train\n",
        "        )\n",
        "        .with_columns(\n",
        "            lesion_size_ratio              = pl.col('tbp_lv_minorAxisMM') / pl.col('clin_size_long_diam_mm'),\n",
        "            lesion_shape_index             = pl.col('tbp_lv_areaMM2') / (pl.col('tbp_lv_perimeterMM') ** 2),\n",
        "            hue_contrast                   = (pl.col('tbp_lv_H') - pl.col('tbp_lv_Hext')).abs(),\n",
        "            luminance_contrast             = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs(),\n",
        "            lesion_color_difference        = (pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2).sqrt(),\n",
        "            border_complexity              = pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_symm_2axis'),\n",
        "            color_uniformity               = pl.col('tbp_lv_color_std_mean') / (pl.col('tbp_lv_radial_color_std_max') + err),\n",
        "        )\n",
        "        .with_columns(\n",
        "            position_distance_3d           = (pl.col('tbp_lv_x') ** 2 + pl.col('tbp_lv_y') ** 2 + pl.col('tbp_lv_z') ** 2).sqrt(),\n",
        "            perimeter_to_area_ratio        = pl.col('tbp_lv_perimeterMM') / pl.col('tbp_lv_areaMM2'),\n",
        "            area_to_perimeter_ratio        = pl.col('tbp_lv_areaMM2') / pl.col('tbp_lv_perimeterMM'),\n",
        "            lesion_visibility_score        = pl.col('tbp_lv_deltaLBnorm') + pl.col('tbp_lv_norm_color'),\n",
        "            combined_anatomical_site       = pl.col('anatom_site_general') + '_' + pl.col('tbp_lv_location'),\n",
        "            symmetry_border_consistency    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border'),\n",
        "            consistency_symmetry_border    = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_norm_border') / (pl.col('tbp_lv_symm_2axis') + pl.col('tbp_lv_norm_border')),\n",
        "        )\n",
        "        .with_columns(\n",
        "            color_consistency              = pl.col('tbp_lv_stdL') / pl.col('tbp_lv_Lext'),\n",
        "            consistency_color              = pl.col('tbp_lv_stdL') * pl.col('tbp_lv_Lext') / (pl.col('tbp_lv_stdL') + pl.col('tbp_lv_Lext')),\n",
        "            size_age_interaction           = pl.col('clin_size_long_diam_mm') * pl.col('age_approx'),\n",
        "            hue_color_std_interaction      = pl.col('tbp_lv_H') * pl.col('tbp_lv_color_std_mean'),\n",
        "            lesion_severity_index          = (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_eccentricity')) / 3,\n",
        "            shape_complexity_index         = pl.col('border_complexity') + pl.col('lesion_shape_index'),\n",
        "            color_contrast_index           = pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL') + pl.col('tbp_lv_deltaLBnorm'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            log_lesion_area                = (pl.col('tbp_lv_areaMM2') + 1).log(),\n",
        "            normalized_lesion_size         = pl.col('clin_size_long_diam_mm') / pl.col('age_approx'),\n",
        "            mean_hue_difference            = (pl.col('tbp_lv_H') + pl.col('tbp_lv_Hext')) / 2,\n",
        "            std_dev_contrast               = ((pl.col('tbp_lv_deltaA') ** 2 + pl.col('tbp_lv_deltaB') ** 2 + pl.col('tbp_lv_deltaL') ** 2) / 3).sqrt(),\n",
        "            color_shape_composite_index    = (pl.col('tbp_lv_color_std_mean') + pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_symm_2axis')) / 3,\n",
        "            lesion_orientation_3d          = pl.arctan2(pl.col('tbp_lv_y'), pl.col('tbp_lv_x')),\n",
        "            overall_color_difference       = (pl.col('tbp_lv_deltaA') + pl.col('tbp_lv_deltaB') + pl.col('tbp_lv_deltaL')) / 3,\n",
        "        )\n",
        "        .with_columns(\n",
        "            symmetry_perimeter_interaction = pl.col('tbp_lv_symm_2axis') * pl.col('tbp_lv_perimeterMM'),\n",
        "            comprehensive_lesion_index     = (pl.col('tbp_lv_area_perim_ratio') + pl.col('tbp_lv_eccentricity') + pl.col('tbp_lv_norm_color') + pl.col('tbp_lv_symm_2axis')) / 4,\n",
        "            color_variance_ratio           = pl.col('tbp_lv_color_std_mean') / pl.col('tbp_lv_stdLExt'),\n",
        "            border_color_interaction       = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color'),\n",
        "            border_color_interaction_2     = pl.col('tbp_lv_norm_border') * pl.col('tbp_lv_norm_color') / (pl.col('tbp_lv_norm_border') + pl.col('tbp_lv_norm_color')),\n",
        "            size_color_contrast_ratio      = pl.col('clin_size_long_diam_mm') / pl.col('tbp_lv_deltaLBnorm'),\n",
        "            age_normalized_nevi_confidence = pl.col('tbp_lv_nevi_confidence') / pl.col('age_approx'),\n",
        "            age_normalized_nevi_confidence_2 = (pl.col('clin_size_long_diam_mm')**2 + pl.col('age_approx')**2).sqrt(),\n",
        "            color_asymmetry_index          = pl.col('tbp_lv_radial_color_std_max') * pl.col('tbp_lv_symm_2axis'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            volume_approximation_3d        = pl.col('tbp_lv_areaMM2') * (pl.col('tbp_lv_x')**2 + pl.col('tbp_lv_y')**2 + pl.col('tbp_lv_z')**2).sqrt(),\n",
        "            color_range                    = (pl.col('tbp_lv_L') - pl.col('tbp_lv_Lext')).abs() + (pl.col('tbp_lv_A') - pl.col('tbp_lv_Aext')).abs() + (pl.col('tbp_lv_B') - pl.col('tbp_lv_Bext')).abs(),\n",
        "            shape_color_consistency        = pl.col('tbp_lv_eccentricity') * pl.col('tbp_lv_color_std_mean'),\n",
        "            border_length_ratio            = pl.col('tbp_lv_perimeterMM') / (2 * np.pi * (pl.col('tbp_lv_areaMM2') / np.pi).sqrt()),\n",
        "            age_size_symmetry_index        = pl.col('age_approx') * pl.col('clin_size_long_diam_mm') * pl.col('tbp_lv_symm_2axis'),\n",
        "            index_age_size_symmetry        = pl.col('age_approx') * pl.col('tbp_lv_areaMM2') * pl.col('tbp_lv_symm_2axis'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            ((pl.col(col) - pl.col(col).mean().over('patient_id')) / (pl.col(col).std().over('patient_id') + err)).alias(f'{col}_patient_norm') for col in (num_cols + new_num_cols)\n",
        "        )\n",
        "        .with_columns(\n",
        "            count_per_patient = pl.col('isic_id').count().over('patient_id'),\n",
        "        )\n",
        "        .with_columns(\n",
        "            pl.col(cat_cols).cast(pl.Categorical)\n",
        "        )\n",
        "        .to_pandas()\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "iwG0C8VLNzXU"
      },
      "outputs": [],
      "source": [
        "def preprocess(df_train, df_test):\n",
        "    global cat_cols\n",
        "\n",
        "    encoder = OneHotEncoder(sparse_output=False, dtype=np.int32, handle_unknown='ignore')\n",
        "    encoder.fit(df_train[cat_cols])\n",
        "\n",
        "    new_cat_cols = [f'onehot_{i}' for i in range(len(encoder.get_feature_names_out()))]\n",
        "\n",
        "    df_train[new_cat_cols] = encoder.transform(df_train[cat_cols])\n",
        "    df_train[new_cat_cols] = df_train[new_cat_cols].astype('category')\n",
        "\n",
        "    df_test[new_cat_cols] = encoder.transform(df_test[cat_cols])\n",
        "    df_test[new_cat_cols] = df_test[new_cat_cols].astype('category')\n",
        "\n",
        "\n",
        "    for col in cat_cols:\n",
        "        feature_cols.remove(col)\n",
        "\n",
        "    feature_cols.extend(new_cat_cols)\n",
        "    cat_cols = new_cat_cols\n",
        "\n",
        "    return df_train, df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Tcy8o-3DvLBF"
      },
      "outputs": [],
      "source": [
        "# df_selfclean = pd.read_csv('/content/ISIC_2024_Challenge_SelfClean_Scores.csv')\n",
        "# df_selfclean.drop(columns=['irrelevant_ranking', 'label_error_ranking'], inplace=True)\n",
        "# df_selfclean.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "9WzoIpR2vhtK"
      },
      "outputs": [],
      "source": [
        "# df_train_merged = df_train.merge(df_selfclean, on=[\"isic_id\", \"patient_id\"])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Q5aCP8gJ4wHS"
      },
      "outputs": [],
      "source": [
        "# count = df_train_merged[(df_train_merged['irrelevant_score'] > 0.99834) & (df_train_merged['target'] == 0)].shape[0]\n",
        "\n",
        "# print(f\"Number of rows where 'irrelevant_score' is more than 0.95 and 'target' is 1: {count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "Gsi5JGaSVBfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1373baab-5771-4b1b-c66e-d8897c3fb1c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold Summary (patients per fold):\n",
            "Fold 0: 206 patients\n",
            "Fold 1: 209 patients\n",
            "Fold 2: 209 patients\n",
            "Fold 3: 209 patients\n",
            "Fold 4: 209 patients\n",
            "Total patients: 1042\n"
          ]
        }
      ],
      "source": [
        "# df_train = pd.read_csv(\"/kaggle/input/isic-2024-challenge/train-metadata.csv\")\n",
        "# df_test = pd.read_csv(\"/kaggle/input/isic-2024-challenge/test-metadata.csv\")\n",
        "\n",
        "TEST_HDF5_FILE_PATH = '/content/test-image.hdf5'\n",
        "err = 1e-5\n",
        "id_col = 'isic_id'\n",
        "\n",
        "train_path = '/content/train-metadata.csv'\n",
        "test_path = '/content/test-metadata.csv'\n",
        "df_train = read_data(train_path)\n",
        "df_train = df_train[~df_train['isic_id'].isin(bad_ids)].reset_index(drop=True)\n",
        "df_test = read_data(test_path)\n",
        "\n",
        "# df_train = df_train.merge(df_selfclean, on=[\"isic_id\", \"patient_id\"])\n",
        "# df_train = df_train[(df_train['target'] == 1) | (df_train['irrelevant_score'] <= 0.99834)].reset_index(drop=True)\n",
        "\n",
        "\n",
        "\n",
        "# df_train = pd.read_csv(\"/content/train-metadata.csv\")\n",
        "# df_train = df_train[~df_train['isic_id'].isin(bad_ids)].reset_index(drop=True)\n",
        "\n",
        "\n",
        "num_folds = 5\n",
        "\n",
        "gkf = GroupKFold(n_splits=num_folds)\n",
        "\n",
        "df_train[\"fold\"] = -1\n",
        "for idx, (train_idx, val_idx) in enumerate(gkf.split(df_train, df_train[\"target\"], groups=df_train[\"patient_id\"])):\n",
        "    df_train.loc[val_idx, \"fold\"] = idx\n",
        "\n",
        "# Add summary\n",
        "fold_summary = df_train.groupby(\"fold\")[\"patient_id\"].nunique().to_dict()\n",
        "total_patients = df_train[\"patient_id\"].nunique()\n",
        "\n",
        "print(f\"Fold Summary (patients per fold):\")\n",
        "for fold, count in fold_summary.items():\n",
        "    if fold != -1:  # Exclude the initialization value\n",
        "        print(f\"Fold {fold}: {count} patients\")\n",
        "print(f\"Total patients: {total_patients}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "JabLqZGfOO1Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1fc9a55b-6fc2-48b1-a063-4e54d6240456"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\t– TRAIN DATAFRAME SHAPE: (400915, 223)\n",
            "\t– TEST DATAFRAME SHAPE: (3, 211)\n",
            "\n",
            "... READS DATA COMPLETE ...\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df_train, df_test = preprocess(df_train, df_test)\n",
        "print(f\"\\t– TRAIN DATAFRAME SHAPE: {df_train.shape}\");\n",
        "print(f\"\\t– TEST DATAFRAME SHAPE: {df_test.shape}\");\n",
        "\n",
        "print(\"\\n... READS DATA COMPLETE ...\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "1gDWBTCzKI-b"
      },
      "outputs": [],
      "source": [
        "\n",
        "pd.options.display.max_columns = None\n",
        "pd.options.display.max_rows = None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "SJoL17vaHGA7"
      },
      "outputs": [],
      "source": [
        "# df_train.isna().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "s8pD_TltdTca"
      },
      "outputs": [],
      "source": [
        "# df_train.dropna(inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "_7Gg0yc-wnId"
      },
      "outputs": [],
      "source": [
        "# df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "xD6BlLRYKYWG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5aaed329-dc60-4cd6-a687-59f860ce731f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400915, 223)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "wFsaZISW8-gL"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "UOk8GUtC7_WN"
      },
      "outputs": [],
      "source": [
        "# df_train[norm_cols] = df_train[norm_cols].apply(lambda col: col.fillna(col.mean()))\n",
        "# df_test[norm_cols] = df_test[norm_cols].apply(lambda col: col.fillna(col.mean()))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "4qz6uhxMK5zG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd630684-2ff7-4e74-ae7c-495a26e78e05"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(400915, 223)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ],
      "source": [
        "df_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "9Hd7ei6GxdPi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "a979f31c-a1f8-46b6-caef-d00c39ba999f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             isic_id  target  patient_id  age_approx   sex  \\\n",
              "379064  ISIC_9454701       1  IP_7696347        70.0  male   \n",
              "\n",
              "       anatom_site_general  clin_size_long_diam_mm          image_type  \\\n",
              "379064      anterior torso                    6.44  TBP tile: close-up   \n",
              "\n",
              "       tbp_tile_type  tbp_lv_A  tbp_lv_Aext  tbp_lv_B  tbp_lv_Bext  tbp_lv_C  \\\n",
              "379064        3D: XP  22.39722     16.25532   26.2166     28.38569  34.48109   \n",
              "\n",
              "        tbp_lv_Cext  tbp_lv_H  tbp_lv_Hext  tbp_lv_L  tbp_lv_Lext  \\\n",
              "379064     32.71059  49.49226       60.202  26.86194     45.42289   \n",
              "\n",
              "        tbp_lv_areaMM2  tbp_lv_area_perim_ratio  tbp_lv_color_std_mean  \\\n",
              "379064        23.41903                 15.54768               3.672147   \n",
              "\n",
              "        tbp_lv_deltaA  tbp_lv_deltaB  tbp_lv_deltaL  tbp_lv_deltaLB  \\\n",
              "379064       6.141898      -2.169089      -18.56094        19.06891   \n",
              "\n",
              "        tbp_lv_deltaLBnorm  tbp_lv_eccentricity       tbp_lv_location  \\\n",
              "379064            16.53963             0.634037  Torso Front Top Half   \n",
              "\n",
              "       tbp_lv_location_simple  tbp_lv_minorAxisMM  tbp_lv_nevi_confidence  \\\n",
              "379064            Torso Front            4.794521                98.48903   \n",
              "\n",
              "        tbp_lv_norm_border  tbp_lv_norm_color  tbp_lv_perimeterMM  \\\n",
              "379064            1.606476           9.457212            19.08171   \n",
              "\n",
              "        tbp_lv_radial_color_std_max  tbp_lv_stdL  tbp_lv_stdLExt  \\\n",
              "379064                       2.9168     8.246979        2.034377   \n",
              "\n",
              "        tbp_lv_symm_2axis  tbp_lv_symm_2axis_angle  tbp_lv_x  tbp_lv_y  \\\n",
              "379064           0.143511                       10  -118.412  1315.588   \n",
              "\n",
              "        tbp_lv_z                                        attribution  \\\n",
              "379064  6.993042  Department of Dermatology, Hospital Clínic de ...   \n",
              "\n",
              "       copyright_license   lesion_id  \\\n",
              "379064          CC-BY-NC  IL_5305785   \n",
              "\n",
              "                                                iddx_full     iddx_1  \\\n",
              "379064  Malignant::Malignant melanocytic proliferation...  Malignant   \n",
              "\n",
              "                                                 iddx_2            iddx_3  \\\n",
              "379064  Malignant melanocytic proliferations (Melanoma)  Melanoma in situ   \n",
              "\n",
              "                                         iddx_4 iddx_5 mel_mitotic_index  \\\n",
              "379064  Melanoma in situ, Superficial spreading                            \n",
              "\n",
              "       mel_thick_mm  tbp_lv_dnn_lesion_confidence  lesion_size_ratio  \\\n",
              "379064           NA                         100.0           0.744491   \n",
              "\n",
              "        lesion_shape_index  hue_contrast  luminance_contrast  \\\n",
              "379064            0.064318      10.70974            18.56095   \n",
              "\n",
              "        lesion_color_difference  border_complexity  color_uniformity  \\\n",
              "379064                19.670698           1.749988           1.25896   \n",
              "\n",
              "        position_distance_3d  perimeter_to_area_ratio  \\\n",
              "379064            1320.92471                 0.814795   \n",
              "\n",
              "        area_to_perimeter_ratio  lesion_visibility_score  \\\n",
              "379064                 1.227302                25.996842   \n",
              "\n",
              "                   combined_anatomical_site  symmetry_border_consistency  \\\n",
              "379064  anterior torso_Torso Front Top Half                     0.230548   \n",
              "\n",
              "        consistency_symmetry_border  color_consistency  consistency_color  \\\n",
              "379064                     0.131743            0.18156           6.979738   \n",
              "\n",
              "        size_age_interaction  hue_color_std_interaction  \\\n",
              "379064                 450.8                 181.742854   \n",
              "\n",
              "        lesion_severity_index  shape_complexity_index  color_contrast_index  \\\n",
              "379064               3.899242                1.814306              1.951499   \n",
              "\n",
              "        log_lesion_area  normalized_lesion_size  mean_hue_difference  \\\n",
              "379064         3.195363                   0.092             54.84713   \n",
              "\n",
              "        std_dev_contrast  color_shape_composite_index  lesion_orientation_3d  \\\n",
              "379064         11.356883                     6.454446               1.660561   \n",
              "\n",
              "        overall_color_difference  symmetry_perimeter_interaction  \\\n",
              "379064                  -4.86271                        2.738445   \n",
              "\n",
              "        comprehensive_lesion_index  color_variance_ratio  \\\n",
              "379064                     6.44561              1.805047   \n",
              "\n",
              "        border_color_interaction  border_color_interaction_2  \\\n",
              "379064                 15.192784                    1.373212   \n",
              "\n",
              "        size_color_contrast_ratio  age_normalized_nevi_confidence  \\\n",
              "379064                   0.389368                        1.406986   \n",
              "\n",
              "        age_normalized_nevi_confidence_2  color_asymmetry_index  \\\n",
              "379064                         70.295616               0.418594   \n",
              "\n",
              "        volume_approximation_3d  color_range  shape_color_consistency  \\\n",
              "379064             30934.775417     26.87194                 2.328276   \n",
              "\n",
              "        border_length_ratio  age_size_symmetry_index  index_age_size_symmetry  \\\n",
              "379064             1.112315                64.694984               235.263009   \n",
              "\n",
              "        age_approx_patient_norm  clin_size_long_diam_mm_patient_norm  \\\n",
              "379064                      NaN                                  NaN   \n",
              "\n",
              "        tbp_lv_A_patient_norm  tbp_lv_Aext_patient_norm  \\\n",
              "379064                    NaN                       NaN   \n",
              "\n",
              "        tbp_lv_B_patient_norm  tbp_lv_Bext_patient_norm  \\\n",
              "379064                    NaN                       NaN   \n",
              "\n",
              "        tbp_lv_C_patient_norm  tbp_lv_Cext_patient_norm  \\\n",
              "379064                    NaN                       NaN   \n",
              "\n",
              "        tbp_lv_H_patient_norm  tbp_lv_Hext_patient_norm  \\\n",
              "379064                    NaN                       NaN   \n",
              "\n",
              "        tbp_lv_L_patient_norm  tbp_lv_Lext_patient_norm  \\\n",
              "379064                    NaN                       NaN   \n",
              "\n",
              "        tbp_lv_areaMM2_patient_norm  tbp_lv_area_perim_ratio_patient_norm  \\\n",
              "379064                          NaN                                   NaN   \n",
              "\n",
              "        tbp_lv_color_std_mean_patient_norm  tbp_lv_deltaA_patient_norm  \\\n",
              "379064                                 NaN                         NaN   \n",
              "\n",
              "        tbp_lv_deltaB_patient_norm  tbp_lv_deltaL_patient_norm  \\\n",
              "379064                         NaN                         NaN   \n",
              "\n",
              "        tbp_lv_deltaLB_patient_norm  tbp_lv_deltaLBnorm_patient_norm  \\\n",
              "379064                          NaN                              NaN   \n",
              "\n",
              "        tbp_lv_eccentricity_patient_norm  tbp_lv_minorAxisMM_patient_norm  \\\n",
              "379064                               NaN                              NaN   \n",
              "\n",
              "        tbp_lv_nevi_confidence_patient_norm  tbp_lv_norm_border_patient_norm  \\\n",
              "379064                                  NaN                              NaN   \n",
              "\n",
              "        tbp_lv_norm_color_patient_norm  tbp_lv_perimeterMM_patient_norm  \\\n",
              "379064                             NaN                              NaN   \n",
              "\n",
              "        tbp_lv_radial_color_std_max_patient_norm  tbp_lv_stdL_patient_norm  \\\n",
              "379064                                       NaN                       NaN   \n",
              "\n",
              "        tbp_lv_stdLExt_patient_norm  tbp_lv_symm_2axis_patient_norm  \\\n",
              "379064                          NaN                             NaN   \n",
              "\n",
              "        tbp_lv_symm_2axis_angle_patient_norm  tbp_lv_x_patient_norm  \\\n",
              "379064                                   NaN                    NaN   \n",
              "\n",
              "        tbp_lv_y_patient_norm  tbp_lv_z_patient_norm  \\\n",
              "379064                    NaN                    NaN   \n",
              "\n",
              "        lesion_size_ratio_patient_norm  lesion_shape_index_patient_norm  \\\n",
              "379064                             NaN                              NaN   \n",
              "\n",
              "        hue_contrast_patient_norm  luminance_contrast_patient_norm  \\\n",
              "379064                        NaN                              NaN   \n",
              "\n",
              "        lesion_color_difference_patient_norm  border_complexity_patient_norm  \\\n",
              "379064                                   NaN                             NaN   \n",
              "\n",
              "        color_uniformity_patient_norm  position_distance_3d_patient_norm  \\\n",
              "379064                            NaN                                NaN   \n",
              "\n",
              "        perimeter_to_area_ratio_patient_norm  \\\n",
              "379064                                   NaN   \n",
              "\n",
              "        area_to_perimeter_ratio_patient_norm  \\\n",
              "379064                                   NaN   \n",
              "\n",
              "        lesion_visibility_score_patient_norm  \\\n",
              "379064                                   NaN   \n",
              "\n",
              "        symmetry_border_consistency_patient_norm  \\\n",
              "379064                                       NaN   \n",
              "\n",
              "        consistency_symmetry_border_patient_norm  \\\n",
              "379064                                       NaN   \n",
              "\n",
              "        color_consistency_patient_norm  consistency_color_patient_norm  \\\n",
              "379064                             NaN                             NaN   \n",
              "\n",
              "        size_age_interaction_patient_norm  \\\n",
              "379064                                NaN   \n",
              "\n",
              "        hue_color_std_interaction_patient_norm  \\\n",
              "379064                                     NaN   \n",
              "\n",
              "        lesion_severity_index_patient_norm  \\\n",
              "379064                                 NaN   \n",
              "\n",
              "        shape_complexity_index_patient_norm  \\\n",
              "379064                                  NaN   \n",
              "\n",
              "        color_contrast_index_patient_norm  log_lesion_area_patient_norm  \\\n",
              "379064                                NaN                           NaN   \n",
              "\n",
              "        normalized_lesion_size_patient_norm  mean_hue_difference_patient_norm  \\\n",
              "379064                                  NaN                               NaN   \n",
              "\n",
              "        std_dev_contrast_patient_norm  \\\n",
              "379064                            NaN   \n",
              "\n",
              "        color_shape_composite_index_patient_norm  \\\n",
              "379064                                       NaN   \n",
              "\n",
              "        lesion_orientation_3d_patient_norm  \\\n",
              "379064                                 NaN   \n",
              "\n",
              "        overall_color_difference_patient_norm  \\\n",
              "379064                                    NaN   \n",
              "\n",
              "        symmetry_perimeter_interaction_patient_norm  \\\n",
              "379064                                          NaN   \n",
              "\n",
              "        comprehensive_lesion_index_patient_norm  \\\n",
              "379064                                      NaN   \n",
              "\n",
              "        color_variance_ratio_patient_norm  \\\n",
              "379064                                NaN   \n",
              "\n",
              "        border_color_interaction_patient_norm  \\\n",
              "379064                                    NaN   \n",
              "\n",
              "        border_color_interaction_2_patient_norm  \\\n",
              "379064                                      NaN   \n",
              "\n",
              "        size_color_contrast_ratio_patient_norm  \\\n",
              "379064                                     NaN   \n",
              "\n",
              "        age_normalized_nevi_confidence_patient_norm  \\\n",
              "379064                                          NaN   \n",
              "\n",
              "        age_normalized_nevi_confidence_2_patient_norm  \\\n",
              "379064                                            NaN   \n",
              "\n",
              "        color_asymmetry_index_patient_norm  \\\n",
              "379064                                 NaN   \n",
              "\n",
              "        volume_approximation_3d_patient_norm  color_range_patient_norm  \\\n",
              "379064                                   NaN                       NaN   \n",
              "\n",
              "        shape_color_consistency_patient_norm  \\\n",
              "379064                                   NaN   \n",
              "\n",
              "        border_length_ratio_patient_norm  \\\n",
              "379064                               NaN   \n",
              "\n",
              "        age_size_symmetry_index_patient_norm  \\\n",
              "379064                                   NaN   \n",
              "\n",
              "        index_age_size_symmetry_patient_norm  count_per_patient  fold  \\\n",
              "379064                                   NaN                  1     2   \n",
              "\n",
              "       onehot_0 onehot_1 onehot_2 onehot_3 onehot_4 onehot_5 onehot_6  \\\n",
              "379064        0        0        1        0        1        0        0   \n",
              "\n",
              "       onehot_7 onehot_8 onehot_9 onehot_10 onehot_11 onehot_12 onehot_13  \\\n",
              "379064        0        0        1         0         0         0         0   \n",
              "\n",
              "       onehot_14 onehot_15 onehot_16 onehot_17 onehot_18 onehot_19 onehot_20  \\\n",
              "379064         0         0         0         0         0         0         0   \n",
              "\n",
              "       onehot_21 onehot_22 onehot_23 onehot_24 onehot_25 onehot_26 onehot_27  \\\n",
              "379064         0         0         0         0         0         0         0   \n",
              "\n",
              "       onehot_28 onehot_29 onehot_30 onehot_31 onehot_32 onehot_33 onehot_34  \\\n",
              "379064         0         0         1         0         0         0         0   \n",
              "\n",
              "       onehot_35 onehot_36 onehot_37 onehot_38 onehot_39 onehot_40 onehot_41  \\\n",
              "379064         0         0         0         1         0         0         1   \n",
              "\n",
              "       onehot_42 onehot_43 onehot_44 onehot_45 onehot_46  \n",
              "379064         0         0         0         0         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a2b423af-82cc-44e8-afbc-09575dca9dbb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>isic_id</th>\n",
              "      <th>target</th>\n",
              "      <th>patient_id</th>\n",
              "      <th>age_approx</th>\n",
              "      <th>sex</th>\n",
              "      <th>anatom_site_general</th>\n",
              "      <th>clin_size_long_diam_mm</th>\n",
              "      <th>image_type</th>\n",
              "      <th>tbp_tile_type</th>\n",
              "      <th>tbp_lv_A</th>\n",
              "      <th>tbp_lv_Aext</th>\n",
              "      <th>tbp_lv_B</th>\n",
              "      <th>tbp_lv_Bext</th>\n",
              "      <th>tbp_lv_C</th>\n",
              "      <th>tbp_lv_Cext</th>\n",
              "      <th>tbp_lv_H</th>\n",
              "      <th>tbp_lv_Hext</th>\n",
              "      <th>tbp_lv_L</th>\n",
              "      <th>tbp_lv_Lext</th>\n",
              "      <th>tbp_lv_areaMM2</th>\n",
              "      <th>tbp_lv_area_perim_ratio</th>\n",
              "      <th>tbp_lv_color_std_mean</th>\n",
              "      <th>tbp_lv_deltaA</th>\n",
              "      <th>tbp_lv_deltaB</th>\n",
              "      <th>tbp_lv_deltaL</th>\n",
              "      <th>tbp_lv_deltaLB</th>\n",
              "      <th>tbp_lv_deltaLBnorm</th>\n",
              "      <th>tbp_lv_eccentricity</th>\n",
              "      <th>tbp_lv_location</th>\n",
              "      <th>tbp_lv_location_simple</th>\n",
              "      <th>tbp_lv_minorAxisMM</th>\n",
              "      <th>tbp_lv_nevi_confidence</th>\n",
              "      <th>tbp_lv_norm_border</th>\n",
              "      <th>tbp_lv_norm_color</th>\n",
              "      <th>tbp_lv_perimeterMM</th>\n",
              "      <th>tbp_lv_radial_color_std_max</th>\n",
              "      <th>tbp_lv_stdL</th>\n",
              "      <th>tbp_lv_stdLExt</th>\n",
              "      <th>tbp_lv_symm_2axis</th>\n",
              "      <th>tbp_lv_symm_2axis_angle</th>\n",
              "      <th>tbp_lv_x</th>\n",
              "      <th>tbp_lv_y</th>\n",
              "      <th>tbp_lv_z</th>\n",
              "      <th>attribution</th>\n",
              "      <th>copyright_license</th>\n",
              "      <th>lesion_id</th>\n",
              "      <th>iddx_full</th>\n",
              "      <th>iddx_1</th>\n",
              "      <th>iddx_2</th>\n",
              "      <th>iddx_3</th>\n",
              "      <th>iddx_4</th>\n",
              "      <th>iddx_5</th>\n",
              "      <th>mel_mitotic_index</th>\n",
              "      <th>mel_thick_mm</th>\n",
              "      <th>tbp_lv_dnn_lesion_confidence</th>\n",
              "      <th>lesion_size_ratio</th>\n",
              "      <th>lesion_shape_index</th>\n",
              "      <th>hue_contrast</th>\n",
              "      <th>luminance_contrast</th>\n",
              "      <th>lesion_color_difference</th>\n",
              "      <th>border_complexity</th>\n",
              "      <th>color_uniformity</th>\n",
              "      <th>position_distance_3d</th>\n",
              "      <th>perimeter_to_area_ratio</th>\n",
              "      <th>area_to_perimeter_ratio</th>\n",
              "      <th>lesion_visibility_score</th>\n",
              "      <th>combined_anatomical_site</th>\n",
              "      <th>symmetry_border_consistency</th>\n",
              "      <th>consistency_symmetry_border</th>\n",
              "      <th>color_consistency</th>\n",
              "      <th>consistency_color</th>\n",
              "      <th>size_age_interaction</th>\n",
              "      <th>hue_color_std_interaction</th>\n",
              "      <th>lesion_severity_index</th>\n",
              "      <th>shape_complexity_index</th>\n",
              "      <th>color_contrast_index</th>\n",
              "      <th>log_lesion_area</th>\n",
              "      <th>normalized_lesion_size</th>\n",
              "      <th>mean_hue_difference</th>\n",
              "      <th>std_dev_contrast</th>\n",
              "      <th>color_shape_composite_index</th>\n",
              "      <th>lesion_orientation_3d</th>\n",
              "      <th>overall_color_difference</th>\n",
              "      <th>symmetry_perimeter_interaction</th>\n",
              "      <th>comprehensive_lesion_index</th>\n",
              "      <th>color_variance_ratio</th>\n",
              "      <th>border_color_interaction</th>\n",
              "      <th>border_color_interaction_2</th>\n",
              "      <th>size_color_contrast_ratio</th>\n",
              "      <th>age_normalized_nevi_confidence</th>\n",
              "      <th>age_normalized_nevi_confidence_2</th>\n",
              "      <th>color_asymmetry_index</th>\n",
              "      <th>volume_approximation_3d</th>\n",
              "      <th>color_range</th>\n",
              "      <th>shape_color_consistency</th>\n",
              "      <th>border_length_ratio</th>\n",
              "      <th>age_size_symmetry_index</th>\n",
              "      <th>index_age_size_symmetry</th>\n",
              "      <th>age_approx_patient_norm</th>\n",
              "      <th>clin_size_long_diam_mm_patient_norm</th>\n",
              "      <th>tbp_lv_A_patient_norm</th>\n",
              "      <th>tbp_lv_Aext_patient_norm</th>\n",
              "      <th>tbp_lv_B_patient_norm</th>\n",
              "      <th>tbp_lv_Bext_patient_norm</th>\n",
              "      <th>tbp_lv_C_patient_norm</th>\n",
              "      <th>tbp_lv_Cext_patient_norm</th>\n",
              "      <th>tbp_lv_H_patient_norm</th>\n",
              "      <th>tbp_lv_Hext_patient_norm</th>\n",
              "      <th>tbp_lv_L_patient_norm</th>\n",
              "      <th>tbp_lv_Lext_patient_norm</th>\n",
              "      <th>tbp_lv_areaMM2_patient_norm</th>\n",
              "      <th>tbp_lv_area_perim_ratio_patient_norm</th>\n",
              "      <th>tbp_lv_color_std_mean_patient_norm</th>\n",
              "      <th>tbp_lv_deltaA_patient_norm</th>\n",
              "      <th>tbp_lv_deltaB_patient_norm</th>\n",
              "      <th>tbp_lv_deltaL_patient_norm</th>\n",
              "      <th>tbp_lv_deltaLB_patient_norm</th>\n",
              "      <th>tbp_lv_deltaLBnorm_patient_norm</th>\n",
              "      <th>tbp_lv_eccentricity_patient_norm</th>\n",
              "      <th>tbp_lv_minorAxisMM_patient_norm</th>\n",
              "      <th>tbp_lv_nevi_confidence_patient_norm</th>\n",
              "      <th>tbp_lv_norm_border_patient_norm</th>\n",
              "      <th>tbp_lv_norm_color_patient_norm</th>\n",
              "      <th>tbp_lv_perimeterMM_patient_norm</th>\n",
              "      <th>tbp_lv_radial_color_std_max_patient_norm</th>\n",
              "      <th>tbp_lv_stdL_patient_norm</th>\n",
              "      <th>tbp_lv_stdLExt_patient_norm</th>\n",
              "      <th>tbp_lv_symm_2axis_patient_norm</th>\n",
              "      <th>tbp_lv_symm_2axis_angle_patient_norm</th>\n",
              "      <th>tbp_lv_x_patient_norm</th>\n",
              "      <th>tbp_lv_y_patient_norm</th>\n",
              "      <th>tbp_lv_z_patient_norm</th>\n",
              "      <th>lesion_size_ratio_patient_norm</th>\n",
              "      <th>lesion_shape_index_patient_norm</th>\n",
              "      <th>hue_contrast_patient_norm</th>\n",
              "      <th>luminance_contrast_patient_norm</th>\n",
              "      <th>lesion_color_difference_patient_norm</th>\n",
              "      <th>border_complexity_patient_norm</th>\n",
              "      <th>color_uniformity_patient_norm</th>\n",
              "      <th>position_distance_3d_patient_norm</th>\n",
              "      <th>perimeter_to_area_ratio_patient_norm</th>\n",
              "      <th>area_to_perimeter_ratio_patient_norm</th>\n",
              "      <th>lesion_visibility_score_patient_norm</th>\n",
              "      <th>symmetry_border_consistency_patient_norm</th>\n",
              "      <th>consistency_symmetry_border_patient_norm</th>\n",
              "      <th>color_consistency_patient_norm</th>\n",
              "      <th>consistency_color_patient_norm</th>\n",
              "      <th>size_age_interaction_patient_norm</th>\n",
              "      <th>hue_color_std_interaction_patient_norm</th>\n",
              "      <th>lesion_severity_index_patient_norm</th>\n",
              "      <th>shape_complexity_index_patient_norm</th>\n",
              "      <th>color_contrast_index_patient_norm</th>\n",
              "      <th>log_lesion_area_patient_norm</th>\n",
              "      <th>normalized_lesion_size_patient_norm</th>\n",
              "      <th>mean_hue_difference_patient_norm</th>\n",
              "      <th>std_dev_contrast_patient_norm</th>\n",
              "      <th>color_shape_composite_index_patient_norm</th>\n",
              "      <th>lesion_orientation_3d_patient_norm</th>\n",
              "      <th>overall_color_difference_patient_norm</th>\n",
              "      <th>symmetry_perimeter_interaction_patient_norm</th>\n",
              "      <th>comprehensive_lesion_index_patient_norm</th>\n",
              "      <th>color_variance_ratio_patient_norm</th>\n",
              "      <th>border_color_interaction_patient_norm</th>\n",
              "      <th>border_color_interaction_2_patient_norm</th>\n",
              "      <th>size_color_contrast_ratio_patient_norm</th>\n",
              "      <th>age_normalized_nevi_confidence_patient_norm</th>\n",
              "      <th>age_normalized_nevi_confidence_2_patient_norm</th>\n",
              "      <th>color_asymmetry_index_patient_norm</th>\n",
              "      <th>volume_approximation_3d_patient_norm</th>\n",
              "      <th>color_range_patient_norm</th>\n",
              "      <th>shape_color_consistency_patient_norm</th>\n",
              "      <th>border_length_ratio_patient_norm</th>\n",
              "      <th>age_size_symmetry_index_patient_norm</th>\n",
              "      <th>index_age_size_symmetry_patient_norm</th>\n",
              "      <th>count_per_patient</th>\n",
              "      <th>fold</th>\n",
              "      <th>onehot_0</th>\n",
              "      <th>onehot_1</th>\n",
              "      <th>onehot_2</th>\n",
              "      <th>onehot_3</th>\n",
              "      <th>onehot_4</th>\n",
              "      <th>onehot_5</th>\n",
              "      <th>onehot_6</th>\n",
              "      <th>onehot_7</th>\n",
              "      <th>onehot_8</th>\n",
              "      <th>onehot_9</th>\n",
              "      <th>onehot_10</th>\n",
              "      <th>onehot_11</th>\n",
              "      <th>onehot_12</th>\n",
              "      <th>onehot_13</th>\n",
              "      <th>onehot_14</th>\n",
              "      <th>onehot_15</th>\n",
              "      <th>onehot_16</th>\n",
              "      <th>onehot_17</th>\n",
              "      <th>onehot_18</th>\n",
              "      <th>onehot_19</th>\n",
              "      <th>onehot_20</th>\n",
              "      <th>onehot_21</th>\n",
              "      <th>onehot_22</th>\n",
              "      <th>onehot_23</th>\n",
              "      <th>onehot_24</th>\n",
              "      <th>onehot_25</th>\n",
              "      <th>onehot_26</th>\n",
              "      <th>onehot_27</th>\n",
              "      <th>onehot_28</th>\n",
              "      <th>onehot_29</th>\n",
              "      <th>onehot_30</th>\n",
              "      <th>onehot_31</th>\n",
              "      <th>onehot_32</th>\n",
              "      <th>onehot_33</th>\n",
              "      <th>onehot_34</th>\n",
              "      <th>onehot_35</th>\n",
              "      <th>onehot_36</th>\n",
              "      <th>onehot_37</th>\n",
              "      <th>onehot_38</th>\n",
              "      <th>onehot_39</th>\n",
              "      <th>onehot_40</th>\n",
              "      <th>onehot_41</th>\n",
              "      <th>onehot_42</th>\n",
              "      <th>onehot_43</th>\n",
              "      <th>onehot_44</th>\n",
              "      <th>onehot_45</th>\n",
              "      <th>onehot_46</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>379064</th>\n",
              "      <td>ISIC_9454701</td>\n",
              "      <td>1</td>\n",
              "      <td>IP_7696347</td>\n",
              "      <td>70.0</td>\n",
              "      <td>male</td>\n",
              "      <td>anterior torso</td>\n",
              "      <td>6.44</td>\n",
              "      <td>TBP tile: close-up</td>\n",
              "      <td>3D: XP</td>\n",
              "      <td>22.39722</td>\n",
              "      <td>16.25532</td>\n",
              "      <td>26.2166</td>\n",
              "      <td>28.38569</td>\n",
              "      <td>34.48109</td>\n",
              "      <td>32.71059</td>\n",
              "      <td>49.49226</td>\n",
              "      <td>60.202</td>\n",
              "      <td>26.86194</td>\n",
              "      <td>45.42289</td>\n",
              "      <td>23.41903</td>\n",
              "      <td>15.54768</td>\n",
              "      <td>3.672147</td>\n",
              "      <td>6.141898</td>\n",
              "      <td>-2.169089</td>\n",
              "      <td>-18.56094</td>\n",
              "      <td>19.06891</td>\n",
              "      <td>16.53963</td>\n",
              "      <td>0.634037</td>\n",
              "      <td>Torso Front Top Half</td>\n",
              "      <td>Torso Front</td>\n",
              "      <td>4.794521</td>\n",
              "      <td>98.48903</td>\n",
              "      <td>1.606476</td>\n",
              "      <td>9.457212</td>\n",
              "      <td>19.08171</td>\n",
              "      <td>2.9168</td>\n",
              "      <td>8.246979</td>\n",
              "      <td>2.034377</td>\n",
              "      <td>0.143511</td>\n",
              "      <td>10</td>\n",
              "      <td>-118.412</td>\n",
              "      <td>1315.588</td>\n",
              "      <td>6.993042</td>\n",
              "      <td>Department of Dermatology, Hospital Clínic de ...</td>\n",
              "      <td>CC-BY-NC</td>\n",
              "      <td>IL_5305785</td>\n",
              "      <td>Malignant::Malignant melanocytic proliferation...</td>\n",
              "      <td>Malignant</td>\n",
              "      <td>Malignant melanocytic proliferations (Melanoma)</td>\n",
              "      <td>Melanoma in situ</td>\n",
              "      <td>Melanoma in situ, Superficial spreading</td>\n",
              "      <td></td>\n",
              "      <td></td>\n",
              "      <td>NA</td>\n",
              "      <td>100.0</td>\n",
              "      <td>0.744491</td>\n",
              "      <td>0.064318</td>\n",
              "      <td>10.70974</td>\n",
              "      <td>18.56095</td>\n",
              "      <td>19.670698</td>\n",
              "      <td>1.749988</td>\n",
              "      <td>1.25896</td>\n",
              "      <td>1320.92471</td>\n",
              "      <td>0.814795</td>\n",
              "      <td>1.227302</td>\n",
              "      <td>25.996842</td>\n",
              "      <td>anterior torso_Torso Front Top Half</td>\n",
              "      <td>0.230548</td>\n",
              "      <td>0.131743</td>\n",
              "      <td>0.18156</td>\n",
              "      <td>6.979738</td>\n",
              "      <td>450.8</td>\n",
              "      <td>181.742854</td>\n",
              "      <td>3.899242</td>\n",
              "      <td>1.814306</td>\n",
              "      <td>1.951499</td>\n",
              "      <td>3.195363</td>\n",
              "      <td>0.092</td>\n",
              "      <td>54.84713</td>\n",
              "      <td>11.356883</td>\n",
              "      <td>6.454446</td>\n",
              "      <td>1.660561</td>\n",
              "      <td>-4.86271</td>\n",
              "      <td>2.738445</td>\n",
              "      <td>6.44561</td>\n",
              "      <td>1.805047</td>\n",
              "      <td>15.192784</td>\n",
              "      <td>1.373212</td>\n",
              "      <td>0.389368</td>\n",
              "      <td>1.406986</td>\n",
              "      <td>70.295616</td>\n",
              "      <td>0.418594</td>\n",
              "      <td>30934.775417</td>\n",
              "      <td>26.87194</td>\n",
              "      <td>2.328276</td>\n",
              "      <td>1.112315</td>\n",
              "      <td>64.694984</td>\n",
              "      <td>235.263009</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a2b423af-82cc-44e8-afbc-09575dca9dbb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a2b423af-82cc-44e8-afbc-09575dca9dbb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a2b423af-82cc-44e8-afbc-09575dca9dbb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        " df_train[df_train['isic_id'] == 'ISIC_9454701']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6QsoG1drVBfa"
      },
      "source": [
        "# Load meta data / review"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "EUPlyzXZVBfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4fa18bb2-69ae-4252-f764-a21885eb2289"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Dataset Summary:\n",
            "Total number of samples: 400915\n",
            "Number of unique patients: 1042\n",
            "Number of positive cases: 393\n",
            "Number of negative cases: 400522\n",
            "Ratio of negative to positive cases: 1019.14:1\n"
          ]
        }
      ],
      "source": [
        "# Set the HDF5 file path\n",
        "TRAIN_HDF5_FILE_PATH = '/content/train-image.hdf5'\n",
        "\n",
        "# are we scoring?\n",
        "scoring = False\n",
        "#check length of test data to see if we are scoring....\n",
        "test_length = len(pd.read_csv(\"/content/test-metadata.csv\"))\n",
        "if test_length > 3:\n",
        "    scoring = True\n",
        "\n",
        "if not scoring:\n",
        "    if full_train_only_when_scoring:\n",
        "        df_train = df_train.head(quick_train_record_count)\n",
        "\n",
        "print(\"\\nOriginal Dataset Summary:\")\n",
        "print(f\"Total number of samples: {len(df_train)}\")\n",
        "print(f\"Number of unique patients: {df_train['patient_id'].nunique()}\")\n",
        "\n",
        "original_positive_cases = df_train['target'].sum()\n",
        "original_total_cases = len(df_train)\n",
        "original_positive_ratio = original_positive_cases / original_total_cases\n",
        "\n",
        "print(f\"Number of positive cases: {original_positive_cases}\")\n",
        "print(f\"Number of negative cases: {original_total_cases - original_positive_cases}\")\n",
        "print(f\"Ratio of negative to positive cases: {(original_total_cases - original_positive_cases) / original_positive_cases:.2f}:1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JA4qilkBVBfa"
      },
      "source": [
        "# Downsample Negatives / Keep All Positives\n",
        "* Keeping just 1% of negatives!\n",
        "* We only use a small subset of the data in each fold for training..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "wsjDQ-NVVBfa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7188dce-996b-4aa3-93fa-82cee9ee7014"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Dataset Summary:\n",
            "Total number of samples: 400915\n",
            "Number of unique patients: 1042\n",
            "Number of positive cases: 393\n",
            "Number of negative cases: 4005\n",
            "New ratio of negative to positive cases: 10.19:1\n"
          ]
        }
      ],
      "source": [
        "#keep all positives\n",
        "df_target_1 = df_train[df_train['target'] == 1]\n",
        "# df_target_1_oversampled = pd.concat([df_target_1] * 3, ignore_index=True)\n",
        "\n",
        "#just use 1% of negatives\n",
        "df_target_0 = df_train[df_train['target'] == 0].sample(frac=0.01, random_state=42)\n",
        "\n",
        "df_train_balanced = pd.concat([df_target_1, df_target_0], ignore_index=True)\n",
        "# df_train_balanced = df_train_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Print balanced dataset summary\n",
        "print(\"Balanced Dataset Summary:\")\n",
        "print(f\"Total number of samples: {len(df_train)}\")\n",
        "print(f\"Number of unique patients: {df_train['patient_id'].nunique()}\")\n",
        "\n",
        "positive_cases = df_train_balanced['target'].sum()\n",
        "total_cases = len(df_train_balanced)\n",
        "positive_ratio = positive_cases / total_cases\n",
        "\n",
        "print(f\"Number of positive cases: {positive_cases}\")\n",
        "print(f\"Number of negative cases: {total_cases - positive_cases}\")\n",
        "print(f\"New ratio of negative to positive cases: {(total_cases - positive_cases) / positive_cases:.2f}:1\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "TKqzw70bQ1Vm"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "# Initialize the scaler\n",
        "scaler = StandardScaler()\n",
        "# Fit the scaler on the training data and transform it\n",
        "df_train_balanced[feature_cols] = scaler.fit_transform(df_train_balanced[feature_cols])\n",
        "\n",
        "# Transform the specified feature columns in the test data using the same scaler\n",
        "df_test[feature_cols] = scaler.transform(df_test[feature_cols])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R8mztoWpVBfb"
      },
      "source": [
        "# ImageNet Setup for Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "coetxlexVBfb"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "from torch.nn import Parameter\n",
        "\n",
        "def gem(x, p=3, eps=1e-4):\n",
        "    return F.avg_pool2d(x.clamp(min=eps), (x.size(-2), x.size(-1))).pow(1.0 / p)\n",
        "\n",
        "class GeM(nn.Module):\n",
        "    def __init__(self, p=3, eps=1e-6, p_trainable=False):\n",
        "        super(GeM, self).__init__()\n",
        "        if p_trainable:\n",
        "            self.p = Parameter(torch.ones(1) * p)\n",
        "        else:\n",
        "            self.p = p\n",
        "        self.eps = eps\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        ret = gem(x, p=self.p, eps=self.eps)\n",
        "        return ret\n",
        "\n",
        "\n",
        "def get_activation(activ_name: str=\"relu\"):\n",
        "    \"\"\"\"\"\"\n",
        "    act_dict = {\n",
        "        \"relu\": nn.ReLU(inplace=True),\n",
        "        \"leakyReLU\" : nn.LeakyReLU(negative_slope=0.01, inplace = True),\n",
        "        \"tanh\": nn.Tanh(),\n",
        "        \"sigmoid\": nn.Sigmoid(),\n",
        "        \"identity\": nn.Identity()}\n",
        "    if activ_name in act_dict:\n",
        "        return act_dict[activ_name]\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "\n",
        "class Conv2dBNActiv(nn.Module):\n",
        "    \"\"\"Conv2d -> (BN ->) -> Activation\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, in_channels, out_channels,\n",
        "        kernel_size, stride, padding,\n",
        "        bias=False, use_bn=True, activ=\"relu\"\n",
        "    ):\n",
        "        \"\"\"\"\"\"\n",
        "        super(Conv2dBNActiv, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Conv2d(\n",
        "            in_channels, out_channels,\n",
        "            kernel_size, stride, padding, bias=bias))\n",
        "        if use_bn:\n",
        "            layers.append(nn.BatchNorm2d(out_channels))\n",
        "\n",
        "        layers.append(get_activation(activ))\n",
        "        self.layers = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward\"\"\"\n",
        "        return self.layers(x)\n",
        "\n",
        "\n",
        "class SpatialAttentionBlock(nn.Module):\n",
        "    \"\"\"Spatial Attention for (C, H, W) feature maps\"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self, in_channels,\n",
        "        out_channels_list,\n",
        "    ):\n",
        "        \"\"\"Initialize\"\"\"\n",
        "        super(SpatialAttentionBlock, self).__init__()\n",
        "        self.n_layers = len(out_channels_list)\n",
        "        channels_list = [in_channels] + out_channels_list\n",
        "        assert self.n_layers > 0\n",
        "        assert channels_list[-1] == 1\n",
        "\n",
        "        for i in range(self.n_layers - 1):\n",
        "            in_chs, out_chs = channels_list[i: i + 2]\n",
        "            layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"relu\")\n",
        "            setattr(self, f\"conv{i + 1}\", layer)\n",
        "\n",
        "        in_chs, out_chs = channels_list[-2:]\n",
        "        layer = Conv2dBNActiv(in_chs, out_chs, 3, 1, 1, activ=\"sigmoid\")\n",
        "        setattr(self, f\"conv{self.n_layers}\", layer)\n",
        "\n",
        "    def forward(self, x):\n",
        "        \"\"\"Forward\"\"\"\n",
        "        h = x\n",
        "        for i in range(self.n_layers):\n",
        "            h = getattr(self, f\"conv{i + 1}\")(h)\n",
        "\n",
        "        h = h * x\n",
        "        return h\n",
        "\n",
        "# class MaskGuidedAttention(nn.Module):\n",
        "#     def __init__(self, in_dim, projected_dim, dropout_rate=0.1, num_heads=8, mask_influence=2.0):\n",
        "#         super(MaskGuidedAttention, self).__init__()\n",
        "#         self.projector = nn.Linear(in_dim, projected_dim)\n",
        "#         self.multihead_attn = nn.MultiheadAttention(embed_dim=projected_dim, num_heads=num_heads, dropout=dropout_rate)\n",
        "#         self.gamma = nn.Parameter(torch.zeros(1) * 0.5)\n",
        "#         self.dropout = nn.Dropout(dropout_rate)\n",
        "#         self.alpha = nn.Parameter(torch.ones(1) * mask_influence)  # Learnable parameter to modulate mask influence\n",
        "#         self.norm = nn.LayerNorm(projected_dim)  # Layer normalization\n",
        "\n",
        "#     def forward(self, x, mask):\n",
        "#         # Reduce mask dimensions to match x\n",
        "#         mask = torch.mean(mask, dim=[2, 3], keepdim=False)  # [batch_size, sequence_length]\n",
        "#         mask = mask.unsqueeze(-1)  # [batch_size, sequence_length, 1]\n",
        "\n",
        "#         # Reshape mask to match the sequence length (seq_len, batch, 1)\n",
        "#         mask = mask.permute(1, 0, 2)  # [sequence_length, batch_size, 1]\n",
        "\n",
        "#         # Project x\n",
        "#         # x = self.projector(x)\n",
        "\n",
        "#         # Apply multi-head attention\n",
        "#         attn_output, attn_weights = self.multihead_attn(x, x, x)\n",
        "#         attn_output = self.norm(attn_output)  # Apply LayerNorm\n",
        "\n",
        "#         # Expand or repeat mask if necessary to match the sequence length of attn_output\n",
        "#         if attn_output.size(0) != mask.size(0):\n",
        "#             mask = F.interpolate(mask.permute(1, 2, 0), size=attn_output.size(0)).permute(2, 0, 1)\n",
        "\n",
        "#         # Apply soft masking\n",
        "#         attn_output = attn_output * (self.alpha * mask)  # Element-wise multiplication with attention output\n",
        "#         attn_output = self.dropout(attn_output)\n",
        "\n",
        "#         # Residual connection\n",
        "#         out = self.gamma * attn_output + x\n",
        "#         return out\n",
        "\n",
        "class MaskGuidedAttention(nn.Module):\n",
        "    def __init__(self, in_dim, dropout_rate=0.0, num_heads=8, mask_influence=1.0):\n",
        "        super(MaskGuidedAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.in_dim = in_dim\n",
        "        self.head_dim = in_dim // num_heads\n",
        "        assert self.head_dim * num_heads == in_dim, \"in_dim must be divisible by num_heads\"\n",
        "\n",
        "        self.W_Q = nn.Linear(in_dim, in_dim)\n",
        "        self.W_K = nn.Linear(in_dim, in_dim)\n",
        "        self.W_V = nn.Linear(in_dim, in_dim)\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.gamma = nn.Parameter(torch.tensor(0.25))\n",
        "        self.alpha = nn.Parameter(torch.tensor(mask_influence))\n",
        "\n",
        "    def forward(self, x, mask):\n",
        "        # x: [seq_len, batch_size, in_dim]\n",
        "        # mask: [batch_size, channels, height, width]\n",
        "        seq_length, batch_size, _ = x.size()\n",
        "\n",
        "        # Reshape x to [batch_size, seq_length, in_dim]\n",
        "        x = x.permute(1, 0, 2)  # [batch_size, seq_length, in_dim]\n",
        "\n",
        "        # Compute spatial dimensions from seq_length\n",
        "        x_height = x_width = int(math.sqrt(seq_length))\n",
        "        if x_height * x_width != seq_length:\n",
        "            raise ValueError(f\"Computed spatial dimensions ({x_height}x{x_width}) do not match seq_length ({seq_length}).\")\n",
        "\n",
        "        # Resize mask to match x's spatial dimensions\n",
        "        mask = F.interpolate(mask, size=(x_height, x_width), mode='bilinear', align_corners=False)  # [batch_size, channels, x_height, x_width]\n",
        "\n",
        "        # If mask has multiple channels, reduce to single channel\n",
        "        if mask.size(1) > 1:\n",
        "            mask = mask.mean(dim=1, keepdim=True)  # [batch_size, 1, x_height, x_width]\n",
        "\n",
        "        # Flatten mask to [batch_size, seq_length]\n",
        "        mask = mask.view(batch_size, -1)\n",
        "\n",
        "        # Normalize and prepare the mask\n",
        "        mask = (mask - mask.mean(dim=1, keepdim=True)) / (mask.std(dim=1, keepdim=True) + 1e-5)\n",
        "        mask = mask.unsqueeze(1).unsqueeze(2)  # [batch_size, 1, 1, seq_length]\n",
        "        mask = mask.expand(-1, self.num_heads, seq_length, -1)  # [batch_size, num_heads, seq_length, seq_length]\n",
        "\n",
        "        # Linear projections for Q, K, V\n",
        "        Q = self.W_Q(x)\n",
        "        K = self.W_K(x)\n",
        "        V = self.W_V(x)\n",
        "\n",
        "        # Reshape for multi-head attention\n",
        "        Q = Q.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        K = K.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "        V = V.view(batch_size, seq_length, self.num_heads, self.head_dim).transpose(1, 2)\n",
        "\n",
        "        # Compute attention scores\n",
        "        attn_scores = torch.matmul(Q, K.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "\n",
        "        # Integrate mask into attention scores\n",
        "        attn_scores = attn_scores + (self.alpha * mask)\n",
        "\n",
        "        # Compute attention weights\n",
        "        attn_weights = F.softmax(attn_scores, dim=-1)\n",
        "        attn_weights = self.dropout(attn_weights)\n",
        "\n",
        "        # Compute attention output\n",
        "        attn_output = torch.matmul(attn_weights, V)\n",
        "\n",
        "        # Concatenate heads\n",
        "        attn_output = attn_output.transpose(1, 2).contiguous().view(batch_size, seq_length, self.in_dim)\n",
        "\n",
        "        # Residual connection\n",
        "        out = self.gamma * attn_output + x\n",
        "\n",
        "        # Permute back to original shape [seq_len, batch_size, in_dim]\n",
        "        out = out.permute(1, 0, 2)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "\n",
        "class SpatialAttentionBlock2(nn.Module):\n",
        "    def __init__(self, in_channels):\n",
        "        super(SpatialAttentionBlock2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(2, 1, kernel_size=7, padding=3)\n",
        "        self.conv2 = nn.Conv2d(in_channels, in_channels, kernel_size=1)  # Added to match original channels\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        avg_out = torch.mean(x, dim=1, keepdim=True)\n",
        "        max_out, _ = torch.max(x, dim=1, keepdim=True)\n",
        "        attn = torch.cat([avg_out, max_out], dim=1)\n",
        "        attn = self.conv1(attn)\n",
        "        attn = self.sigmoid(attn)\n",
        "\n",
        "        # Apply the attention mask to the original input\n",
        "        return self.conv2(attn * x)\n",
        "\n",
        "class EnhancedSegmentationHead(nn.Module):\n",
        "    def __init__(self, in_channels, mid_channels=288, out_channels=1, dropout_prob=0.1):\n",
        "        super(EnhancedSegmentationHead, self).__init__()\n",
        "\n",
        "        # Downsample block 1\n",
        "        self.conv1 = nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1)\n",
        "        self.norm1 = nn.GroupNorm(32, mid_channels)  # Using GroupNorm instead of InstanceNorm\n",
        "        self.mish1 = nn.Mish(inplace=True)\n",
        "        self.dropout1 = nn.Dropout2d(0.15)\n",
        "\n",
        "        # Downsample block 2\n",
        "        self.conv2 = nn.Conv2d(mid_channels, mid_channels, kernel_size=3, padding=1)\n",
        "        self.norm2 = nn.GroupNorm(32, mid_channels)\n",
        "        self.mish2 = nn.Mish(inplace=True)\n",
        "        self.dropout2 = nn.Dropout2d(0.05)\n",
        "\n",
        "        # Upsample block 1\n",
        "        self.upsample1 = nn.ConvTranspose2d(mid_channels, mid_channels // 2, kernel_size=2, stride=2)\n",
        "        self.norm3 = nn.GroupNorm(16, mid_channels // 2)\n",
        "        self.mish3 = nn.Mish(inplace=True)\n",
        "        self.dropout3 = nn.Dropout2d(0.05)\n",
        "\n",
        "        # Upsample block 2\n",
        "        self.upsample2 = nn.ConvTranspose2d(mid_channels // 2, mid_channels // 4, kernel_size=2, stride=2)\n",
        "        self.norm4 = nn.GroupNorm(8, mid_channels // 4)\n",
        "        self.mish4 = nn.Mish(inplace=True)\n",
        "        self.dropout4 = nn.Dropout2d(0.1)\n",
        "\n",
        "        # Spatial Attention\n",
        "        self.attention = SpatialAttentionBlock2(in_channels // 8)\n",
        "\n",
        "        # Final convolution layer to reduce channels\n",
        "        self.conv_out = nn.Conv2d(72, out_channels, kernel_size=1)\n",
        "        self.dropout5 = nn.Dropout2d(0.5)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Downsampling path\n",
        "        x = self.conv1(x)\n",
        "        x = self.norm1(x)\n",
        "        x = self.mish1(x)\n",
        "        x = self.dropout1(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.norm2(x)\n",
        "        x = self.mish2(x)\n",
        "        x = self.dropout2(x)\n",
        "\n",
        "        # Upsampling path\n",
        "        x = self.upsample1(x)\n",
        "        x = self.norm3(x)\n",
        "        x = self.mish3(x)\n",
        "        x = self.dropout3(x)\n",
        "\n",
        "        x = self.upsample2(x)\n",
        "        x = self.norm4(x)\n",
        "        x = self.mish4(x)\n",
        "        x = self.attention(x)  # Apply attention before final conv layer\n",
        "\n",
        "        # Output\n",
        "        out = self.conv_out(x)\n",
        "        out = self.dropout5(out)\n",
        "        out = self.sigmoid(out)  # Final activation without dropout to ensure stability\n",
        "\n",
        "        return out\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "UEq1aeE8VBfb"
      },
      "outputs": [],
      "source": [
        "# import torch.nn as nn\n",
        "# import timm\n",
        "\n",
        "# class ISICModel(nn.Module):\n",
        "#     def __init__(self, backbone='tiny_vit_21m_224.dist_in22k_ft_in1k', num_classes=2, pretrained=False, freeze_base_model=False):\n",
        "#         super(ISICModel, self).__init__()\n",
        "\n",
        "#         # Encoder setup with the specified backbone\n",
        "#         self.encoder = timm.create_model(\n",
        "#             backbone,\n",
        "#             pretrained=pretrained,\n",
        "#         )\n",
        "\n",
        "#         # Freeze the encoder if required\n",
        "#         if freeze_base_model:\n",
        "#             self.freeze_encoder(True)\n",
        "\n",
        "#         self.nb_fts = self.encoder.num_features\n",
        "#         self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "#         self.spatial_attention = SpatialAttentionBlock(in_channels=self.nb_fts, out_channels_list=[self.nb_fts // 2, 1])\n",
        "\n",
        "#         self.dropout = nn.Dropout2d(0.0)\n",
        "\n",
        "# #         self.segmentation_head = nn.Sequential(\n",
        "# #             UNetBlock(self.nb_fts, self.nb_fts // 2),\n",
        "# #             nn.ConvTranspose2d(self.nb_fts // 2, self.nb_fts // 4, kernel_size=2, stride=2),\n",
        "# #             UNetBlock(self.nb_fts // 4, self.nb_fts // 4),\n",
        "# #             nn.Conv2d(self.nb_fts // 4, 1, kernel_size=1),\n",
        "# #             nn.Dropout2d(0.4),\n",
        "# #             nn.Sigmoid()\n",
        "# #         )\n",
        "\n",
        "# #         self.segmentation_head = nn.Sequential(\n",
        "# #         nn.Conv2d(self.nb_fts, 1, kernel_size=1),\n",
        "# #         nn.Sigmoid()\n",
        "# #     )\n",
        "\n",
        "#         self.segmentation_head = ComplexSegmentationHeadWithDropout(in_channels=self.nb_fts)\n",
        "#         self.gem_pooling = GeM(p=3, p_trainable=True)\n",
        "#         self.mask_guided_attention = MaskGuidedAttention(in_dim=self.nb_fts, projected_dim=self.nb_fts, dropout_rate=0.25)\n",
        "\n",
        "\n",
        "# #         self.head = nn.Sequential(\n",
        "# #                 SpatialAttentionBlock(self.nb_fts, [self.nb_fts ,1]),\n",
        "# #                 nn.AdaptiveAvgPool2d(output_size=1),\n",
        "# #                 nn.Flatten(start_dim=1),\n",
        "# #                 nn.Linear(self.nb_fts, 128),\n",
        "# #                 nn.LayerNorm(128),\n",
        "# #                 nn.Mish(inplace=True),\n",
        "# #                 nn.Dropout(0.5),\n",
        "# #                 nn.Linear(128, 2))\n",
        "\n",
        "# #         Classification head with the specified number of classes\n",
        "#         self.head = nn.Sequential(\n",
        "#             nn.Linear(self.nb_fts, 128),\n",
        "#             nn.LayerNorm(128),\n",
        "#             nn.Mish(),\n",
        "#             nn.Dropout(0.25),\n",
        "#             nn.Linear(128, num_classes),\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.encoder.forward_features(x)\n",
        "#         x = self.spatial_attention(x)\n",
        "#         x = self.dropout(x)\n",
        "#         seg_mask = self.segmentation_head(x)\n",
        "\n",
        "#         # Classification Path\n",
        "#         cls_x = x.flatten(2).permute(2, 0, 1)  # Reshape to [seq_len, batch, nb_fts] for attention\n",
        "#         cls_x = self.mask_guided_attention(cls_x, seg_mask)\n",
        "#         cls_x = self.gem_pooling(x)\n",
        "#         cls_x = cls_x.flatten(1)\n",
        "#         cls_x = self.head(cls_x)\n",
        "\n",
        "#         return cls_x\n",
        "\n",
        "#     def freeze_encoder(self, flag):\n",
        "#         for param in self.encoder.parameters():\n",
        "#             param.requires_grad = not flag"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "5TgMY3rlOYci"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import timm\n",
        "\n",
        "class ISICModel(nn.Module):\n",
        "    def __init__(self,\n",
        "                 backbone='tiny_vit_21m_224.dist_in22k_ft_in1k',\n",
        "                 num_classes=2,\n",
        "                 pretrained=False,\n",
        "                 freeze_base_model=False):\n",
        "        super(ISICModel, self).__init__()\n",
        "\n",
        "        # Encoder setup with the specified backbone\n",
        "        self.encoder = timm.create_model(\n",
        "            backbone,\n",
        "            pretrained=pretrained,\n",
        "        )\n",
        "\n",
        "        # Freeze the encoder if required\n",
        "        if freeze_base_model:\n",
        "            self.freeze_encoder(True)\n",
        "\n",
        "        self.nb_fts = self.encoder.num_features\n",
        "        self.gap = nn.AdaptiveAvgPool2d(1)\n",
        "        self.spatial_attention = SpatialAttentionBlock(in_channels=self.nb_fts, out_channels_list=[self.nb_fts // 2, 1])\n",
        "        self.dropout = nn.Dropout2d(0.0)\n",
        "\n",
        "        self.segmentation_head = EnhancedSegmentationHead(in_channels=self.nb_fts)\n",
        "        self.gem_pooling = GeM(p=3, p_trainable=True)\n",
        "        self.mask_guided_attention = MaskGuidedAttention(\n",
        "            in_dim=self.nb_fts,\n",
        "            dropout_rate=0.0,\n",
        "            num_heads=8,\n",
        "            mask_influence=1.00\n",
        "        )\n",
        "\n",
        "        # Embedding layers for categorical features\n",
        "#         self.embeddings = nn.ModuleList([\n",
        "#             nn.Embedding(num_categories, min(50, (num_categories + 1) // 2))\n",
        "#             for num_categories in categorical_cardinalities\n",
        "#         ])\n",
        "\n",
        "        # Tabular feature processing network\n",
        "        self.tabular_net = nn.Sequential(\n",
        "            nn.Linear(124, 512),  # Assuming 82 tabular features\n",
        "            nn.BatchNorm1d(512),\n",
        "            nn.SiLU(),  # Activation changed to Mish\n",
        "            nn.Dropout(0.3),  # Dropout increased to 0.5\n",
        "            nn.Linear(512, 128),\n",
        "            nn.BatchNorm1d(128),\n",
        "            nn.SiLU()  # Activation changed to Mish\n",
        "            # nn.Dropout(0.3),  # Dropout increased to 0.5\n",
        "        )\n",
        "\n",
        "        # Combined classification head\n",
        "        self.head = nn.Sequential(\n",
        "            nn.Linear(self.nb_fts + 128, 128),  # Concatenate image features and tabular features\n",
        "            # nn.BatchNorm1d(128),\n",
        "            # nn.Mish(),\n",
        "            nn.Dropout(0.5),\n",
        "            nn.Linear(128, num_classes),\n",
        "        )\n",
        "\n",
        "    def forward(self, image, tabular_data):\n",
        "            # Image Path\n",
        "            x = self.encoder.forward_features(image)\n",
        "            x = self.spatial_attention(x)\n",
        "            x = self.dropout(x)\n",
        "            seg_mask = self.segmentation_head(x)\n",
        "\n",
        "            # Classification Path\n",
        "            cls_x = x.flatten(2).permute(2, 0, 1)  # Reshape to [seq_len, batch, nb_fts] for attention\n",
        "            cls_x = self.mask_guided_attention(cls_x, seg_mask)\n",
        "            cls_x = self.gem_pooling(x)\n",
        "            cls_x = cls_x.flatten(1)\n",
        "\n",
        "            # Tabular Path\n",
        "            tabular_feat = self.tabular_net(tabular_data)\n",
        "\n",
        "            # Concatenate Image and Tabular Features\n",
        "            combined_features = torch.cat((cls_x, tabular_feat), dim=1)\n",
        "\n",
        "            # Final Classification\n",
        "            output = self.head(combined_features)\n",
        "\n",
        "            return output, seg_mask\n",
        "\n",
        "    def freeze_encoder(self, flag):\n",
        "        for param in self.encoder.parameters():\n",
        "            param.requires_grad = not flag\n",
        "\n",
        "model = ISICModel()\n",
        "\n",
        "# Separate the parameters into different groups\n",
        "segmentation_params = list(model.segmentation_head.parameters())\n",
        "classification_params = list(model.head.parameters())\n",
        "encoder_params = list(model.encoder.parameters())\n",
        "attention_params = list(model.spatial_attention.parameters()) + \\\n",
        "                   list(model.gem_pooling.parameters()) + \\\n",
        "                   list(model.mask_guided_attention.parameters())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dp4SlJiaVBfb"
      },
      "outputs": [],
      "source": [
        "def setup_isic_model(backbone='tiny_vit_21m_224.dist_in22k_ft_in1k', num_classes=2, freeze_base_model=False, pretrained=True):\n",
        "    model = ISICModel(backbone=backbone, num_classes=num_classes, pretrained=pretrained, freeze_base_model=freeze_base_model)\n",
        "    return model.to(device)\n",
        "\n",
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "        f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aZ5tEK0XVBfb"
      },
      "source": [
        "# Data Loading / Image Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "nNWs5G6dVBfb"
      },
      "outputs": [],
      "source": [
        "# class ISICDataset(Dataset):\n",
        "#     def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
        "#         self.hdf5_file = hdf5_file\n",
        "#         self.isic_ids = isic_ids\n",
        "#         self.targets = targets\n",
        "#         self.transform = transform\n",
        "\n",
        "#     def get_labels(self):\n",
        "#         return self.targets\n",
        "\n",
        "#     def __len__(self):\n",
        "#         return len(self.isic_ids)\n",
        "\n",
        "#     def __getitem__(self, idx):\n",
        "#         with h5py.File(self.hdf5_file, 'r') as f:\n",
        "#             img_bytes = f[self.isic_ids[idx]][()]\n",
        "\n",
        "#         img = Image.open(io.BytesIO(img_bytes))\n",
        "#         img = np.array(img)  # Convert PIL Image to numpy array\n",
        "\n",
        "#         if self.transform:\n",
        "#             transformed = self.transform(image=img)\n",
        "#             img = transformed['image']\n",
        "\n",
        "#         if self.targets is not None:\n",
        "#             target = self.targets[idx]\n",
        "#         else:\n",
        "#             target = torch.tensor(-1)  # Dummy target for test set\n",
        "\n",
        "#         return img, target\n",
        "\n",
        "# # Prepare augmentation\n",
        "# aug_transform = A.Compose([\n",
        "\n",
        "#     A.RandomRotate90(),\n",
        "#     A.Flip(),\n",
        "# #     A.ShiftScaleRotate(shift_limit=0.0, scale_limit=0.15, rotate_limit=90, p=0.5),\n",
        "#     A.RandomBrightnessContrast(brightness_limit=0.18, contrast_limit=0.12, p=0.5),\n",
        "# #     A.OpticalDistortion(distort_limit=0.5, shift_limit=0.0, p=0.7),\n",
        "\n",
        "#     A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=5, val_shift_limit=1, p=0.5),\n",
        "\n",
        "# #     A.ElasticTransform(alpha=0.2, sigma=6.0, alpha_affine=20.0, p=0.5),\n",
        "#     A.Resize(224, 224),\n",
        "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#     ToTensorV2(),\n",
        "# ])\n",
        "\n",
        "# base_transform = A.Compose([\n",
        "#     A.Resize(224, 224),\n",
        "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#     ToTensorV2(),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "DqYkgHnUXSRe"
      },
      "outputs": [],
      "source": [
        "# aug_transform = A.Compose([\n",
        "\n",
        "#     A.Transpose(p=0.5),\n",
        "#     A.VerticalFlip(p=0.5),\n",
        "#     A.HorizontalFlip(p=0.5),\n",
        "#     A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.75),\n",
        "#     A.OneOf([\n",
        "#         A.MotionBlur(blur_limit=5),\n",
        "#         A.MedianBlur(blur_limit=5),\n",
        "#         A.GaussianBlur(blur_limit=5),\n",
        "#         A.GaussNoise(var_limit=(5.0, 20.0)),\n",
        "#     ], p=0.7),\n",
        "\n",
        "#     A.OneOf([\n",
        "#         A.OpticalDistortion(distort_limit=1.0),\n",
        "#         A.GridDistortion(num_steps=5, distort_limit=1.),\n",
        "#         A.ElasticTransform(alpha=3),\n",
        "#     ], p=0.7),\n",
        "\n",
        "#     A.CLAHE(clip_limit=4.0, p=0.7),\n",
        "#     A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=20, val_shift_limit=10, p=0.5),\n",
        "#     A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.1, rotate_limit=15, border_mode=0, p=0.85),\n",
        "#     A.Resize(224, 224),\n",
        "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#     ToTensorV2(),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wUuLZSIsOfVO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "deca8c67-7052-44ed-d1da-f45a06b15c04"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-744a7e03a2e0>:41: DeprecationWarning: Flip is deprecated. Consider using HorizontalFlip, VerticalFlip, RandomRotate90 or D4.\n",
            "  A.Flip(),\n"
          ]
        }
      ],
      "source": [
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, hdf5_file, isic_ids, tabular_features=None, targets=None, transform=None):\n",
        "        self.hdf5_file = hdf5_file\n",
        "        self.isic_ids = isic_ids\n",
        "        self.tabular_features = tabular_features  # Add tabular features here\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def get_labels(self):\n",
        "        return self.targets\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.isic_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        with h5py.File(self.hdf5_file, 'r') as f:\n",
        "            img_bytes = f[self.isic_ids[idx]][()]\n",
        "\n",
        "        img = Image.open(io.BytesIO(img_bytes))\n",
        "        img = np.array(img)  # Convert PIL Image to numpy array\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed['image']\n",
        "\n",
        "        tabular_feat = None\n",
        "        if self.tabular_features is not None:\n",
        "            tabular_feat = self.tabular_features[idx]  # Get the tabular features for this index\n",
        "\n",
        "        if self.targets is not None:\n",
        "            target = self.targets[idx]\n",
        "        else:\n",
        "            target = torch.tensor(-1)  # Dummy target for test set\n",
        "\n",
        "        return img, tabular_feat, target  # Return image, tabular features, and target\n",
        "\n",
        "# Prepare Augmentations\n",
        "aug_transform = A.Compose([\n",
        "\n",
        "    A.RandomRotate90(),\n",
        "    A.Flip(),\n",
        "    A.ShiftScaleRotate(shift_limit=0.0, scale_limit=0.15, rotate_limit=90, p=0.5),\n",
        "    A.RandomBrightnessContrast(brightness_limit=0.18, contrast_limit=0.12, p=0.5),\n",
        "    A.OpticalDistortion(distort_limit=0.5, shift_limit=0.0, p=0.7),\n",
        "\n",
        "    A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=5, val_shift_limit=1, p=0.5),\n",
        "\n",
        "    A.ElasticTransform(alpha=0.2, sigma=6.0, p=0.5),\n",
        "    A.Resize(224, 224, interpolation=cv2.INTER_CUBIC),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "base_transform = A.Compose([\n",
        "    A.Resize(224, 224,interpolation=cv2.INTER_CUBIC),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "i70iI5i80GXH"
      },
      "outputs": [],
      "source": [
        "# aug_transform = A.Compose([\n",
        "\n",
        "#     A.RandomRotate90(),\n",
        "#     A.Flip(),\n",
        "#     A.ShiftScaleRotate(shift_limit=0.0, scale_limit=0.15, rotate_limit=90, p=0.5),\n",
        "#     A.RandomBrightnessContrast(brightness_limit=0.18, contrast_limit=0.12, p=0.5),\n",
        "#     A.OpticalDistortion(distort_limit=0.5, shift_limit=0.0, p=0.7),\n",
        "\n",
        "#     A.HueSaturationValue(hue_shift_limit=3, sat_shift_limit=5, val_shift_limit=1, p=0.5),\n",
        "\n",
        "#     A.ElasticTransform(alpha=0.2, sigma=6.0, p=0.5),\n",
        "#     A.Resize(224, 224),\n",
        "#     A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "#     ToTensorV2(),\n",
        "# ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_j1s9RZUVBfc"
      },
      "source": [
        "# Visualize image augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "eA2qDHYwVBfc"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from torchvision.utils import make_grid\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "import cv2\n",
        "\n",
        "def visualize_augmentations_positive(dataset, num_samples=3, num_augmentations=5, figsize=(20, 10)):\n",
        "    # Find positive samples\n",
        "    positive_samples = []\n",
        "    for i in range(len(dataset)):\n",
        "        _, label = dataset[i]\n",
        "        if label == 1:  # Assuming 1 is the positive class\n",
        "            positive_samples.append(i)\n",
        "\n",
        "        if len(positive_samples) == num_samples:\n",
        "            break\n",
        "\n",
        "    if len(positive_samples) < num_samples:\n",
        "        print(f\"Warning: Only found {len(positive_samples)} positive samples.\")\n",
        "\n",
        "    fig, axes = plt.subplots(num_samples, num_augmentations + 1, figsize=figsize)\n",
        "    fig.suptitle(\"Original and Augmented Versions of Positive Samples\", fontsize=16)\n",
        "\n",
        "    for sample_num, sample_idx in enumerate(positive_samples):\n",
        "        # Get a single sample\n",
        "        original_image, label = dataset[sample_idx]\n",
        "\n",
        "        # If the image is already a tensor (due to ToTensorV2 in the transform), convert it back to numpy\n",
        "        if isinstance(original_image, torch.Tensor):\n",
        "            original_image = original_image.permute(1, 2, 0).numpy()\n",
        "\n",
        "        # Reverse the normalization\n",
        "        mean = np.array([0.485, 0.456, 0.406])\n",
        "        std = np.array([0.229, 0.224, 0.225])\n",
        "        original_image = (original_image * std + mean) * 255\n",
        "        original_image = original_image.astype(np.uint8)\n",
        "\n",
        "        # Display original image\n",
        "        axes[sample_num, 0].imshow(original_image)\n",
        "        axes[sample_num, 0].axis('off')\n",
        "        axes[sample_num, 0].set_title(\"Original\", fontsize=10)\n",
        "\n",
        "        # Apply and display augmentations\n",
        "        for aug_num in range(num_augmentations):\n",
        "            augmented = dataset.transform(image=original_image)['image']\n",
        "            # If the result is a tensor, convert it back to numpy\n",
        "            if isinstance(augmented, torch.Tensor):\n",
        "                augmented = augmented.permute(1, 2, 0).numpy()\n",
        "            # Reverse the normalization\n",
        "            augmented = (augmented * std + mean) * 255\n",
        "            augmented = augmented.astype(np.uint8)\n",
        "\n",
        "            axes[sample_num, aug_num + 1].imshow(augmented)\n",
        "            axes[sample_num, aug_num + 1].axis('off')\n",
        "            axes[sample_num, aug_num + 1].set_title(f\"Augmented {aug_num + 1}\", fontsize=10)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "augtest_dataset = ISICDataset(\n",
        "    hdf5_file=TRAIN_HDF5_FILE_PATH,\n",
        "    isic_ids=df_train['isic_id'].values,\n",
        "    targets=df_train['target'].values,\n",
        "    transform=aug_transform,\n",
        ")\n",
        "\n",
        "# visualize_augmentations_positive(augtest_dataset)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qrIxhizJVBfc"
      },
      "source": [
        "# Scoring code from https://www.kaggle.com/code/metric/isic-pauc-abovetpr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "_bhuDJD_VBfc"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
        "\n",
        "def score(solution: pd.DataFrame, submission: pd.DataFrame, row_id_column_name: str, min_tpr: float=0.80) -> float:\n",
        "\n",
        "    del solution[row_id_column_name]\n",
        "    del submission[row_id_column_name]\n",
        "\n",
        "    # rescale the target. set 0s to 1s and 1s to 0s (since sklearn only has max_fpr)\n",
        "    v_gt = abs(np.asarray(solution.values)-1)\n",
        "\n",
        "    # flip the submissions to their compliments\n",
        "    v_pred = -1.0*np.asarray(submission.values)\n",
        "\n",
        "    max_fpr = abs(1-min_tpr)\n",
        "\n",
        "    # using sklearn.metric functions: (1) roc_curve and (2) auc\n",
        "    fpr, tpr, _ = roc_curve(v_gt, v_pred, sample_weight=None)\n",
        "    if max_fpr is None or max_fpr == 1:\n",
        "        return auc(fpr, tpr)\n",
        "    if max_fpr <= 0 or max_fpr > 1:\n",
        "        raise ValueError(\"Expected min_tpr in range [0, 1), got: %r\" % min_tpr)\n",
        "\n",
        "    # Add a single point at max_fpr by linear interpolation\n",
        "    stop = np.searchsorted(fpr, max_fpr, \"right\")\n",
        "    x_interp = [fpr[stop - 1], fpr[stop]]\n",
        "    y_interp = [tpr[stop - 1], tpr[stop]]\n",
        "    tpr = np.append(tpr[:stop], np.interp(max_fpr, x_interp, y_interp))\n",
        "    fpr = np.append(fpr[:stop], max_fpr)\n",
        "    partial_auc = auc(fpr, tpr)\n",
        "\n",
        "    return(partial_auc)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aNXwaHOPVBfc"
      },
      "source": [
        "# Train / CV"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "Rx1a2zv0VBfc"
      },
      "outputs": [],
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=2, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        if isinstance(alpha, (float, int)):  # Removed 'long' as it's not needed in Python 3\n",
        "            self.alpha = torch.tensor([alpha, 1 - alpha])\n",
        "        elif isinstance(alpha, list):\n",
        "            self.alpha = torch.tensor(alpha)\n",
        "        else:\n",
        "            self.alpha = alpha\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim() > 2:\n",
        "            input = input.view(input.size(0), input.size(1), -1)  # N,C,H,W -> N,C,H*W\n",
        "            input = input.transpose(1, 2)    # N,C,H*W -> N,H*W,C\n",
        "            input = input.contiguous().view(-1, input.size(2))   # N,H*W,C -> N*H*W,C\n",
        "        target = target.view(-1, 1)\n",
        "\n",
        "        # Updated to include dim argument\n",
        "        logpt = F.log_softmax(input, dim=-1)\n",
        "        logpt = logpt.gather(1, target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = logpt.exp()\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type() != input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            at = self.alpha.gather(0, target.view(-1))\n",
        "            logpt = logpt * at\n",
        "\n",
        "        loss = -1 * (1 - pt) ** self.gamma * logpt\n",
        "        if self.size_average:\n",
        "            return loss.mean()\n",
        "        else:\n",
        "            return loss.sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "tmwwydkHQybU"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class CombinedLoss(nn.Module):\n",
        "    def __init__(self, gamma=0.25, smooth=1e-6):\n",
        "        super(CombinedLoss, self).__init__()\n",
        "        self.dice_loss = DiceLoss(smooth)\n",
        "        self.cross_entropy = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 1.25]),label_smoothing=0.1) # weight=torch.tensor([1.0, 1.25]\n",
        "        self.gamma = gamma\n",
        "\n",
        "    def forward(self, logits, seg_mask, class_targets):\n",
        "        # Self-supervised segmentation part\n",
        "        pseudo_targets = generate_pseudo_targets(seg_mask)\n",
        "        seg_loss = self.dice_loss(seg_mask, pseudo_targets)\n",
        "\n",
        "        # Classification part\n",
        "        class_loss = self.cross_entropy(logits, class_targets)\n",
        "\n",
        "        # Combine losses\n",
        "        loss = self.gamma * seg_loss + 0.75 * class_loss\n",
        "        return loss\n",
        "\n",
        "class DiceLoss(nn.Module):\n",
        "    def __init__(self, smooth=1e-6):\n",
        "        super(DiceLoss, self).__init__()\n",
        "        self.smooth = smooth\n",
        "\n",
        "    def forward(self, logits, targets):\n",
        "        probs = torch.sigmoid(logits)\n",
        "        num = probs * targets  # Element-wise multiplication between the predicted and true masks\n",
        "        num = 2 * torch.sum(num, dim=(1, 2, 3))  # Sum over all dimensions except batch size\n",
        "\n",
        "        den = probs + targets  # Element-wise addition\n",
        "        den = torch.sum(den, dim=(1, 2, 3))  # Sum over all dimensions except batch size\n",
        "\n",
        "        dice = (num + self.smooth) / (den + self.smooth)\n",
        "        return 1 - dice.mean()  # Dice Loss is 1 - Dice Coefficient\n",
        "\n",
        "def generate_pseudo_targets(seg_mask):\n",
        "    # Generate pseudo-targets from the segmentation mask (this can be the model's own predictions)\n",
        "    return torch.sigmoid(seg_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pEDB51NxVBfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "022a1f24-e236-43b3-c541-1bfffb171d5b"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Fold 1/5\n",
            "tensor([0.5488, 5.6230], dtype=torch.float64)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.31s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Train Loss: 0.4322, Val Loss: 0.3787\n",
            "Fold 1, Epoch 1 pAUC Score: 0.1222\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1222\n",
            "\n",
            "Epoch 2/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:14<00:00,  2.65s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.88s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Train Loss: 0.3837, Val Loss: 0.3563\n",
            "Fold 1, Epoch 2 pAUC Score: 0.1396\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1396\n",
            "\n",
            "Epoch 3/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.84s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Train Loss: 0.3669, Val Loss: 0.3433\n",
            "Fold 1, Epoch 3 pAUC Score: 0.1556\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1556\n",
            "\n",
            "Epoch 4/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Train Loss: 0.3536, Val Loss: 0.3362\n",
            "Fold 1, Epoch 4 pAUC Score: 0.1629\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1629\n",
            "\n",
            "Epoch 5/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:07<00:00,  2.41s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.09s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Train Loss: 0.3480, Val Loss: 0.3287\n",
            "Fold 1, Epoch 5 pAUC Score: 0.1667\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1667\n",
            "\n",
            "Epoch 6/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.35s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Train Loss: 0.3418, Val Loss: 0.3233\n",
            "Fold 1, Epoch 6 pAUC Score: 0.1681\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1681\n",
            "\n",
            "Epoch 7/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.32s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.28s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 - Train Loss: 0.3378, Val Loss: 0.3195\n",
            "Fold 1, Epoch 7 pAUC Score: 0.1683\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1683\n",
            "\n",
            "Epoch 8/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:07<00:00,  2.43s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 - Train Loss: 0.3368, Val Loss: 0.3192\n",
            "Fold 1, Epoch 8 pAUC Score: 0.1679\n",
            "\n",
            "Epoch 9/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.24s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.19s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 - Train Loss: 0.3329, Val Loss: 0.3158\n",
            "Fold 1, Epoch 9 pAUC Score: 0.1676\n",
            "\n",
            "Epoch 10/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.37s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.05s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 - Train Loss: 0.3276, Val Loss: 0.3187\n",
            "Fold 1, Epoch 10 pAUC Score: 0.1691\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1691\n",
            "\n",
            "Epoch 11/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:07<00:00,  2.40s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.18s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 - Train Loss: 0.3254, Val Loss: 0.3153\n",
            "Fold 1, Epoch 11 pAUC Score: 0.1701\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1701\n",
            "\n",
            "Epoch 12/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.38s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 - Train Loss: 0.3226, Val Loss: 0.3131\n",
            "Fold 1, Epoch 12 pAUC Score: 0.1673\n",
            "\n",
            "Epoch 13/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.28s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 - Train Loss: 0.3201, Val Loss: 0.3120\n",
            "Fold 1, Epoch 13 pAUC Score: 0.1689\n",
            "\n",
            "Epoch 14/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.98s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 - Train Loss: 0.3182, Val Loss: 0.3101\n",
            "Fold 1, Epoch 14 pAUC Score: 0.1679\n",
            "\n",
            "Epoch 15/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.25s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.24s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 - Train Loss: 0.3178, Val Loss: 0.3111\n",
            "Fold 1, Epoch 15 pAUC Score: 0.1676\n",
            "\n",
            "Epoch 16/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.07s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 - Train Loss: 0.3186, Val Loss: 0.3093\n",
            "Fold 1, Epoch 16 pAUC Score: 0.1693\n",
            "\n",
            "Epoch 17/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.31s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.08s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 - Train Loss: 0.3175, Val Loss: 0.3077\n",
            "Fold 1, Epoch 17 pAUC Score: 0.1705\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 1 with pAUC Score: 0.1705\n",
            "\n",
            "Epoch 18/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.31s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.15s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 - Train Loss: 0.3122, Val Loss: 0.3081\n",
            "Fold 1, Epoch 18 pAUC Score: 0.1698\n",
            "\n",
            "Epoch 19/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.32s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.25s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 - Train Loss: 0.3126, Val Loss: 0.3083\n",
            "Fold 1, Epoch 19 pAUC Score: 0.1694\n",
            "\n",
            "Epoch 20/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.33s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 - Train Loss: 0.3159, Val Loss: 0.3078\n",
            "Fold 1, Epoch 20 pAUC Score: 0.1701\n",
            "\n",
            "Epoch 21/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.32s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.05s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 - Train Loss: 0.3090, Val Loss: 0.3075\n",
            "Fold 1, Epoch 21 pAUC Score: 0.1696\n",
            "\n",
            "Epoch 22/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 - Train Loss: 0.3102, Val Loss: 0.3060\n",
            "Fold 1, Epoch 22 pAUC Score: 0.1702\n",
            "\n",
            "Epoch 23/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 - Train Loss: 0.3076, Val Loss: 0.3068\n",
            "Fold 1, Epoch 23 pAUC Score: 0.1696\n",
            "\n",
            "Epoch 24/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 - Train Loss: 0.3069, Val Loss: 0.3070\n",
            "Fold 1, Epoch 24 pAUC Score: 0.1697\n",
            "\n",
            "Epoch 25/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.24s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.64s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 - Train Loss: 0.3055, Val Loss: 0.3058\n",
            "Fold 1, Epoch 25 pAUC Score: 0.1703\n",
            "\n",
            "Epoch 26/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.28s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.12s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 - Train Loss: 0.3035, Val Loss: 0.3051\n",
            "Fold 1, Epoch 26 pAUC Score: 0.1698\n",
            "\n",
            "Epoch 27/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:59<00:00,  2.13s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 - Train Loss: 0.3054, Val Loss: 0.3057\n",
            "Fold 1, Epoch 27 pAUC Score: 0.1687\n",
            "\n",
            "Epoch 28/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.32s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 - Train Loss: 0.3057, Val Loss: 0.3055\n",
            "Fold 1, Epoch 28 pAUC Score: 0.1680\n",
            "\n",
            "Epoch 29/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.25s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 - Train Loss: 0.3041, Val Loss: 0.3050\n",
            "Fold 1, Epoch 29 pAUC Score: 0.1687\n",
            "\n",
            "Epoch 30/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.28s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 - Train Loss: 0.3016, Val Loss: 0.3056\n",
            "Fold 1, Epoch 30 pAUC Score: 0.1698\n",
            "\n",
            "Epoch 31/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.98s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 - Train Loss: 0.3039, Val Loss: 0.3055\n",
            "Fold 1, Epoch 31 pAUC Score: 0.1683\n",
            "\n",
            "Epoch 32/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.27s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 - Train Loss: 0.3022, Val Loss: 0.3065\n",
            "Fold 1, Epoch 32 pAUC Score: 0.1690\n",
            "\n",
            "Epoch 33/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:00<00:00,  2.17s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.09s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 - Train Loss: 0.3034, Val Loss: 0.3061\n",
            "Fold 1, Epoch 33 pAUC Score: 0.1689\n",
            "\n",
            "Epoch 34/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:00<00:00,  2.15s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 - Train Loss: 0.3025, Val Loss: 0.3054\n",
            "Fold 1, Epoch 34 pAUC Score: 0.1684\n",
            "\n",
            "Epoch 35/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.25s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.08s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 - Train Loss: 0.2987, Val Loss: 0.3058\n",
            "Fold 1, Epoch 35 pAUC Score: 0.1676\n",
            "\n",
            "Epoch 36/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:00<00:00,  2.15s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.14s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 - Train Loss: 0.2998, Val Loss: 0.3060\n",
            "Fold 1, Epoch 36 pAUC Score: 0.1657\n",
            "\n",
            "Epoch 37/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.27s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.10s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 - Train Loss: 0.2996, Val Loss: 0.3056\n",
            "Fold 1, Epoch 37 pAUC Score: 0.1670\n",
            "\n",
            "Epoch 38/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.30s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.92s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 - Train Loss: 0.2991, Val Loss: 0.3056\n",
            "Fold 1, Epoch 38 pAUC Score: 0.1676\n",
            "\n",
            "Epoch 39/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:08<00:00,  2.45s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 - Train Loss: 0.2986, Val Loss: 0.3055\n",
            "Fold 1, Epoch 39 pAUC Score: 0.1683\n",
            "\n",
            "Epoch 40/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:09<00:00,  2.47s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.01s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 - Train Loss: 0.2977, Val Loss: 0.3055\n",
            "Fold 1, Epoch 40 pAUC Score: 0.1676\n",
            "\n",
            "Epoch 41/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.11s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 - Train Loss: 0.3026, Val Loss: 0.3061\n",
            "Fold 1, Epoch 41 pAUC Score: 0.1677\n",
            "\n",
            "Epoch 42/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.27s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.93s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 - Train Loss: 0.3048, Val Loss: 0.3056\n",
            "Fold 1, Epoch 42 pAUC Score: 0.1666\n",
            "\n",
            "Epoch 43/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.32s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.05s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 - Train Loss: 0.2995, Val Loss: 0.3056\n",
            "Fold 1, Epoch 43 pAUC Score: 0.1666\n",
            "\n",
            "Epoch 44/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 - Train Loss: 0.2996, Val Loss: 0.3059\n",
            "Fold 1, Epoch 44 pAUC Score: 0.1661\n",
            "\n",
            "Epoch 45/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.97s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 - Train Loss: 0.2981, Val Loss: 0.3065\n",
            "Fold 1, Epoch 45 pAUC Score: 0.1673\n",
            "\n",
            "Epoch 46/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.00s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 - Train Loss: 0.2999, Val Loss: 0.3060\n",
            "Fold 1, Epoch 46 pAUC Score: 0.1672\n",
            "\n",
            "Epoch 47/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.27s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 - Train Loss: 0.2953, Val Loss: 0.3061\n",
            "Fold 1, Epoch 47 pAUC Score: 0.1669\n",
            "\n",
            "Epoch 48/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.37s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  2.00s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 - Train Loss: 0.2987, Val Loss: 0.3054\n",
            "Fold 1, Epoch 48 pAUC Score: 0.1666\n",
            "\n",
            "Epoch 49/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.30s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.13s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 - Train Loss: 0.2986, Val Loss: 0.3056\n",
            "Fold 1, Epoch 49 pAUC Score: 0.1659\n",
            "\n",
            "Epoch 50/50\n",
            "Train: 3475, Val: 923, Train Pos Ratio: 8.89%, Val Pos Ratio: 9.10%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:58<00:00,  2.10s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:11<00:00,  2.78s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 - Train Loss: 0.2965, Val Loss: 0.3056\n",
            "Fold 1, Epoch 50 pAUC Score: 0.1659\n",
            "\n",
            "Fold 2/5\n",
            "tensor([0.5497, 5.5294], dtype=torch.float64)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.24s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.63s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Train Loss: 0.4307, Val Loss: 0.3667\n",
            "Fold 2, Epoch 1 pAUC Score: 0.0793\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.0793\n",
            "\n",
            "Epoch 2/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.54s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Train Loss: 0.3852, Val Loss: 0.3469\n",
            "Fold 2, Epoch 2 pAUC Score: 0.0981\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.0981\n",
            "\n",
            "Epoch 3/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.21s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:13<00:00,  3.32s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Train Loss: 0.3676, Val Loss: 0.3351\n",
            "Fold 2, Epoch 3 pAUC Score: 0.1120\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1120\n",
            "\n",
            "Epoch 4/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Train Loss: 0.3537, Val Loss: 0.3284\n",
            "Fold 2, Epoch 4 pAUC Score: 0.1202\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1202\n",
            "\n",
            "Epoch 5/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.34s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Train Loss: 0.3468, Val Loss: 0.3236\n",
            "Fold 2, Epoch 5 pAUC Score: 0.1303\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1303\n",
            "\n",
            "Epoch 6/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.80s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Train Loss: 0.3389, Val Loss: 0.3192\n",
            "Fold 2, Epoch 6 pAUC Score: 0.1374\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1374\n",
            "\n",
            "Epoch 7/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.33s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 - Train Loss: 0.3385, Val Loss: 0.3163\n",
            "Fold 2, Epoch 7 pAUC Score: 0.1431\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1431\n",
            "\n",
            "Epoch 8/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.25s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.86s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8 - Train Loss: 0.3292, Val Loss: 0.3133\n",
            "Fold 2, Epoch 8 pAUC Score: 0.1430\n",
            "\n",
            "Epoch 9/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.30s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.84s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9 - Train Loss: 0.3275, Val Loss: 0.3130\n",
            "Fold 2, Epoch 9 pAUC Score: 0.1411\n",
            "\n",
            "Epoch 10/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10 - Train Loss: 0.3246, Val Loss: 0.3112\n",
            "Fold 2, Epoch 10 pAUC Score: 0.1460\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1460\n",
            "\n",
            "Epoch 11/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:08<00:00,  2.45s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.76s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11 - Train Loss: 0.3210, Val Loss: 0.3113\n",
            "Fold 2, Epoch 11 pAUC Score: 0.1486\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1486\n",
            "\n",
            "Epoch 12/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:09<00:00,  2.49s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12 - Train Loss: 0.3211, Val Loss: 0.3098\n",
            "Fold 2, Epoch 12 pAUC Score: 0.1505\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1505\n",
            "\n",
            "Epoch 13/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.38s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.97s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 13 - Train Loss: 0.3190, Val Loss: 0.3083\n",
            "Fold 2, Epoch 13 pAUC Score: 0.1554\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1554\n",
            "\n",
            "Epoch 14/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.43s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 14 - Train Loss: 0.3160, Val Loss: 0.3067\n",
            "Fold 2, Epoch 14 pAUC Score: 0.1571\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1571\n",
            "\n",
            "Epoch 15/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:00<00:00,  2.17s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.57s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 15 - Train Loss: 0.3154, Val Loss: 0.3070\n",
            "Fold 2, Epoch 15 pAUC Score: 0.1521\n",
            "\n",
            "Epoch 16/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.20s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.66s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 16 - Train Loss: 0.3131, Val Loss: 0.3079\n",
            "Fold 2, Epoch 16 pAUC Score: 0.1541\n",
            "\n",
            "Epoch 17/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.57s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 17 - Train Loss: 0.3148, Val Loss: 0.3053\n",
            "Fold 2, Epoch 17 pAUC Score: 0.1589\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 2 with pAUC Score: 0.1589\n",
            "\n",
            "Epoch 18/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.33s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 18 - Train Loss: 0.3122, Val Loss: 0.3050\n",
            "Fold 2, Epoch 18 pAUC Score: 0.1584\n",
            "\n",
            "Epoch 19/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.71s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 19 - Train Loss: 0.3108, Val Loss: 0.3053\n",
            "Fold 2, Epoch 19 pAUC Score: 0.1572\n",
            "\n",
            "Epoch 20/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.34s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 20 - Train Loss: 0.3094, Val Loss: 0.3037\n",
            "Fold 2, Epoch 20 pAUC Score: 0.1556\n",
            "\n",
            "Epoch 21/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.38s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.64s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 21 - Train Loss: 0.3088, Val Loss: 0.3058\n",
            "Fold 2, Epoch 21 pAUC Score: 0.1535\n",
            "\n",
            "Epoch 22/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.39s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.79s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 22 - Train Loss: 0.3054, Val Loss: 0.3043\n",
            "Fold 2, Epoch 22 pAUC Score: 0.1547\n",
            "\n",
            "Epoch 23/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:09<00:00,  2.49s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.00s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 23 - Train Loss: 0.3051, Val Loss: 0.3073\n",
            "Fold 2, Epoch 23 pAUC Score: 0.1527\n",
            "\n",
            "Epoch 24/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.19s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.57s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 24 - Train Loss: 0.3061, Val Loss: 0.3038\n",
            "Fold 2, Epoch 24 pAUC Score: 0.1537\n",
            "\n",
            "Epoch 25/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.25s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.57s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 25 - Train Loss: 0.3041, Val Loss: 0.3044\n",
            "Fold 2, Epoch 25 pAUC Score: 0.1542\n",
            "\n",
            "Epoch 26/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:00<00:00,  2.16s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.34s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 26 - Train Loss: 0.3029, Val Loss: 0.3033\n",
            "Fold 2, Epoch 26 pAUC Score: 0.1544\n",
            "\n",
            "Epoch 27/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.21s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 27 - Train Loss: 0.3015, Val Loss: 0.3020\n",
            "Fold 2, Epoch 27 pAUC Score: 0.1530\n",
            "\n",
            "Epoch 28/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.30s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.77s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 28 - Train Loss: 0.3016, Val Loss: 0.3022\n",
            "Fold 2, Epoch 28 pAUC Score: 0.1570\n",
            "\n",
            "Epoch 29/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.35s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.73s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 29 - Train Loss: 0.3027, Val Loss: 0.3039\n",
            "Fold 2, Epoch 29 pAUC Score: 0.1503\n",
            "\n",
            "Epoch 30/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.30s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.73s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 30 - Train Loss: 0.3019, Val Loss: 0.3042\n",
            "Fold 2, Epoch 30 pAUC Score: 0.1462\n",
            "\n",
            "Epoch 31/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 31 - Train Loss: 0.2989, Val Loss: 0.3020\n",
            "Fold 2, Epoch 31 pAUC Score: 0.1494\n",
            "\n",
            "Epoch 32/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.56s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 32 - Train Loss: 0.3007, Val Loss: 0.3025\n",
            "Fold 2, Epoch 32 pAUC Score: 0.1466\n",
            "\n",
            "Epoch 33/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:10<00:00,  2.51s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.76s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 33 - Train Loss: 0.3010, Val Loss: 0.3033\n",
            "Fold 2, Epoch 33 pAUC Score: 0.1451\n",
            "\n",
            "Epoch 34/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.34s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.72s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 34 - Train Loss: 0.2996, Val Loss: 0.3032\n",
            "Fold 2, Epoch 34 pAUC Score: 0.1444\n",
            "\n",
            "Epoch 35/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.75s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 35 - Train Loss: 0.2968, Val Loss: 0.3036\n",
            "Fold 2, Epoch 35 pAUC Score: 0.1434\n",
            "\n",
            "Epoch 36/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:06<00:00,  1.69s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 36 - Train Loss: 0.2972, Val Loss: 0.3042\n",
            "Fold 2, Epoch 36 pAUC Score: 0.1444\n",
            "\n",
            "Epoch 37/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.82s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 37 - Train Loss: 0.2977, Val Loss: 0.3036\n",
            "Fold 2, Epoch 37 pAUC Score: 0.1448\n",
            "\n",
            "Epoch 38/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.30s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.80s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 38 - Train Loss: 0.2976, Val Loss: 0.3034\n",
            "Fold 2, Epoch 38 pAUC Score: 0.1452\n",
            "\n",
            "Epoch 39/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.34s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.76s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 39 - Train Loss: 0.2976, Val Loss: 0.3028\n",
            "Fold 2, Epoch 39 pAUC Score: 0.1460\n",
            "\n",
            "Epoch 40/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:09<00:00,  2.47s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.79s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 40 - Train Loss: 0.2963, Val Loss: 0.3028\n",
            "Fold 2, Epoch 40 pAUC Score: 0.1452\n",
            "\n",
            "Epoch 41/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.80s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 41 - Train Loss: 0.2962, Val Loss: 0.3026\n",
            "Fold 2, Epoch 41 pAUC Score: 0.1443\n",
            "\n",
            "Epoch 42/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:10<00:00,  2.51s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 42 - Train Loss: 0.2961, Val Loss: 0.3028\n",
            "Fold 2, Epoch 42 pAUC Score: 0.1451\n",
            "\n",
            "Epoch 43/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.34s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.85s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 43 - Train Loss: 0.2963, Val Loss: 0.3021\n",
            "Fold 2, Epoch 43 pAUC Score: 0.1438\n",
            "\n",
            "Epoch 44/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.35s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.81s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 44 - Train Loss: 0.2943, Val Loss: 0.3025\n",
            "Fold 2, Epoch 44 pAUC Score: 0.1451\n",
            "\n",
            "Epoch 45/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.81s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 45 - Train Loss: 0.2940, Val Loss: 0.3029\n",
            "Fold 2, Epoch 45 pAUC Score: 0.1440\n",
            "\n",
            "Epoch 46/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.28s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 46 - Train Loss: 0.2951, Val Loss: 0.3029\n",
            "Fold 2, Epoch 46 pAUC Score: 0.1429\n",
            "\n",
            "Epoch 47/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.79s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 47 - Train Loss: 0.2953, Val Loss: 0.3026\n",
            "Fold 2, Epoch 47 pAUC Score: 0.1442\n",
            "\n",
            "Epoch 48/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.37s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.87s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 48 - Train Loss: 0.2954, Val Loss: 0.3025\n",
            "Fold 2, Epoch 48 pAUC Score: 0.1450\n",
            "\n",
            "Epoch 49/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.27s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.48s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 49 - Train Loss: 0.2971, Val Loss: 0.3025\n",
            "Fold 2, Epoch 49 pAUC Score: 0.1441\n",
            "\n",
            "Epoch 50/50\n",
            "Train: 3572, Val: 826, Train Pos Ratio: 9.04%, Val Pos Ratio: 8.47%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.19s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 50 - Train Loss: 0.2941, Val Loss: 0.3028\n",
            "Fold 2, Epoch 50 pAUC Score: 0.1438\n",
            "\n",
            "Fold 3/5\n",
            "tensor([0.5498, 5.5157], dtype=torch.float64)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Epoch 1/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.18s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.03s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1 - Train Loss: 0.4423, Val Loss: 0.3711\n",
            "Fold 3, Epoch 1 pAUC Score: 0.1253\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1253\n",
            "\n",
            "Epoch 2/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.32s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.98s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2 - Train Loss: 0.3890, Val Loss: 0.3362\n",
            "Fold 3, Epoch 2 pAUC Score: 0.1527\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1527\n",
            "\n",
            "Epoch 3/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3 - Train Loss: 0.3721, Val Loss: 0.3218\n",
            "Fold 3, Epoch 3 pAUC Score: 0.1585\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1585\n",
            "\n",
            "Epoch 4/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.32s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.94s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4 - Train Loss: 0.3595, Val Loss: 0.3146\n",
            "Fold 3, Epoch 4 pAUC Score: 0.1623\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1623\n",
            "\n",
            "Epoch 5/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.20s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5 - Train Loss: 0.3536, Val Loss: 0.3103\n",
            "Fold 3, Epoch 5 pAUC Score: 0.1598\n",
            "\n",
            "Epoch 6/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.27s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.04s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6 - Train Loss: 0.3454, Val Loss: 0.3067\n",
            "Fold 3, Epoch 6 pAUC Score: 0.1626\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1626\n",
            "\n",
            "Epoch 7/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:07<00:00,  2.42s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.86s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7 - Train Loss: 0.3394, Val Loss: 0.3036\n",
            "Fold 3, Epoch 7 pAUC Score: 0.1630\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1630\n",
            "\n",
            "Epoch 8/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Training:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.25s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.11s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 - Train Loss: 0.3400, Val Loss: 0.3027\n",
            "Fold 3, Epoch 8 pAUC Score: 0.1621\n",
            "\n",
            "Epoch 9/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.31s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.83s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 - Train Loss: 0.3335, Val Loss: 0.3022\n",
            "Fold 3, Epoch 9 pAUC Score: 0.1629\n",
            "\n",
            "Epoch 10/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:59<00:00,  2.11s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.08s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 - Train Loss: 0.3311, Val Loss: 0.3015\n",
            "Fold 3, Epoch 10 pAUC Score: 0.1654\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1654\n",
            "\n",
            "Epoch 11/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.34s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11 - Train Loss: 0.3244, Val Loss: 0.3008\n",
            "Fold 3, Epoch 11 pAUC Score: 0.1671\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1671\n",
            "\n",
            "Epoch 12/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:59<00:00,  2.14s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.49s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12 - Train Loss: 0.3258, Val Loss: 0.3003\n",
            "Fold 3, Epoch 12 pAUC Score: 0.1648\n",
            "\n",
            "Epoch 13/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.96s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13 - Train Loss: 0.3200, Val Loss: 0.2997\n",
            "Fold 3, Epoch 13 pAUC Score: 0.1660\n",
            "\n",
            "Epoch 14/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.99s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14 - Train Loss: 0.3187, Val Loss: 0.2984\n",
            "Fold 3, Epoch 14 pAUC Score: 0.1676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1676\n",
            "\n",
            "Epoch 15/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.19s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.03s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15 - Train Loss: 0.3150, Val Loss: 0.2991\n",
            "Fold 3, Epoch 15 pAUC Score: 0.1655\n",
            "\n",
            "Epoch 16/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.19s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16 - Train Loss: 0.3158, Val Loss: 0.2989\n",
            "Fold 3, Epoch 16 pAUC Score: 0.1683\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1683\n",
            "\n",
            "Epoch 17/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.38s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.91s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17 - Train Loss: 0.3154, Val Loss: 0.2993\n",
            "Fold 3, Epoch 17 pAUC Score: 0.1669\n",
            "\n",
            "Epoch 18/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.93s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18 - Train Loss: 0.3114, Val Loss: 0.2988\n",
            "Fold 3, Epoch 18 pAUC Score: 0.1673\n",
            "\n",
            "Epoch 19/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.22s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19 - Train Loss: 0.3116, Val Loss: 0.2994\n",
            "Fold 3, Epoch 19 pAUC Score: 0.1684\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1684\n",
            "\n",
            "Epoch 20/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  2.23s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20 - Train Loss: 0.3069, Val Loss: 0.2983\n",
            "Fold 3, Epoch 20 pAUC Score: 0.1720\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1720\n",
            "\n",
            "Epoch 21/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.27s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.89s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21 - Train Loss: 0.3081, Val Loss: 0.2990\n",
            "Fold 3, Epoch 21 pAUC Score: 0.1693\n",
            "\n",
            "Epoch 22/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.21s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.95s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22 - Train Loss: 0.3078, Val Loss: 0.3006\n",
            "Fold 3, Epoch 22 pAUC Score: 0.1685\n",
            "\n",
            "Epoch 23/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.20s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23 - Train Loss: 0.3067, Val Loss: 0.3000\n",
            "Fold 3, Epoch 23 pAUC Score: 0.1696\n",
            "\n",
            "Epoch 24/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24 - Train Loss: 0.3059, Val Loss: 0.2987\n",
            "Fold 3, Epoch 24 pAUC Score: 0.1685\n",
            "\n",
            "Epoch 25/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:03<00:00,  2.26s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.96s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25 - Train Loss: 0.3020, Val Loss: 0.2984\n",
            "Fold 3, Epoch 25 pAUC Score: 0.1703\n",
            "\n",
            "Epoch 26/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.24s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26 - Train Loss: 0.3035, Val Loss: 0.2987\n",
            "Fold 3, Epoch 26 pAUC Score: 0.1704\n",
            "\n",
            "Epoch 27/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.33s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.88s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27 - Train Loss: 0.3039, Val Loss: 0.2985\n",
            "Fold 3, Epoch 27 pAUC Score: 0.1702\n",
            "\n",
            "Epoch 28/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:00<00:00,  2.18s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.37s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28 - Train Loss: 0.3006, Val Loss: 0.2990\n",
            "Fold 3, Epoch 28 pAUC Score: 0.1680\n",
            "\n",
            "Epoch 29/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:59<00:00,  2.14s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.02s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29 - Train Loss: 0.2989, Val Loss: 0.2991\n",
            "Fold 3, Epoch 29 pAUC Score: 0.1686\n",
            "\n",
            "Epoch 30/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.20s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.05s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30 - Train Loss: 0.3007, Val Loss: 0.3004\n",
            "Fold 3, Epoch 30 pAUC Score: 0.1725\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New best model saved for fold 3 with pAUC Score: 0.1725\n",
            "\n",
            "Epoch 31/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:06<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:07<00:00,  1.91s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31 - Train Loss: 0.3001, Val Loss: 0.2999\n",
            "Fold 3, Epoch 31 pAUC Score: 0.1710\n",
            "\n",
            "Epoch 32/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:05<00:00,  2.36s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:09<00:00,  2.38s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32 - Train Loss: 0.2963, Val Loss: 0.3008\n",
            "Fold 3, Epoch 32 pAUC Score: 0.1704\n",
            "\n",
            "Epoch 33/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:04<00:00,  2.29s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.61s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33 - Train Loss: 0.2979, Val Loss: 0.3008\n",
            "Fold 3, Epoch 33 pAUC Score: 0.1706\n",
            "\n",
            "Epoch 34/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:57<00:00,  2.06s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.66s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34 - Train Loss: 0.2981, Val Loss: 0.3003\n",
            "Fold 3, Epoch 34 pAUC Score: 0.1708\n",
            "\n",
            "Epoch 35/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:58<00:00,  2.09s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.60s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35 - Train Loss: 0.2992, Val Loss: 0.3014\n",
            "Fold 3, Epoch 35 pAUC Score: 0.1716\n",
            "\n",
            "Epoch 36/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.19s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.75s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36 - Train Loss: 0.2964, Val Loss: 0.3009\n",
            "Fold 3, Epoch 36 pAUC Score: 0.1697\n",
            "\n",
            "Epoch 37/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [00:57<00:00,  2.07s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:13<00:00,  3.41s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37 - Train Loss: 0.2949, Val Loss: 0.3007\n",
            "Fold 3, Epoch 37 pAUC Score: 0.1691\n",
            "\n",
            "Epoch 38/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:00<00:00,  2.14s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:10<00:00,  2.61s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 38 - Train Loss: 0.2963, Val Loss: 0.3011\n",
            "Fold 3, Epoch 38 pAUC Score: 0.1699\n",
            "\n",
            "Epoch 39/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:01<00:00,  2.21s/it]\n",
            "<ipython-input-35-89ba35077f3a>:70: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
            "Evaluating: 100%|██████████| 4/4 [00:08<00:00,  2.20s/it]\n",
            "<ipython-input-35-89ba35077f3a>:43: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  scaler = GradScaler()  # Updated from the deprecated version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 39 - Train Loss: 0.2980, Val Loss: 0.3017\n",
            "Fold 3, Epoch 39 pAUC Score: 0.1702\n",
            "\n",
            "Epoch 40/50\n",
            "Train: 3519, Val: 879, Train Pos Ratio: 9.07%, Val Pos Ratio: 8.42%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\rTraining:   0%|          | 0/28 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:557: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "<ipython-input-35-89ba35077f3a>:52: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
            "  with autocast():  # Updated to the new autocast syntax\n",
            "Training: 100%|██████████| 28/28 [01:02<00:00,  1.28it/s]"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "import numpy as np\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from torch.utils.data import Dataset, DataLoader, WeightedRandomSampler, SequentialSampler, RandomSampler\n",
        "from torch.autograd import Variable\n",
        "\n",
        "# def train_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device):\n",
        "#     scaler = GradScaler()\n",
        "\n",
        "#     # Training phase\n",
        "#     model.train()\n",
        "#     for inputs, targets in tqdm(train_loader, desc=\"Training\"):\n",
        "#         inputs, targets = inputs.to(device), targets.to(device)\n",
        "#         optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "#         with autocast():\n",
        "#             outputs = model(inputs)\n",
        "#             loss = criterion(outputs, targets)\n",
        "\n",
        "#         scaler.scale(loss).backward()\n",
        "#         scaler.step(optimizer)\n",
        "#         scaler.update()\n",
        "\n",
        "#     # Evaluation phase\n",
        "#     model.eval()\n",
        "#     val_targets, val_outputs = [], []\n",
        "#     with torch.no_grad(), autocast():\n",
        "#         for inputs, targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "#             inputs, targets = inputs.to(device), targets.to(device)\n",
        "#             outputs = model(inputs)\n",
        "#             val_targets.append(targets.cpu())\n",
        "#             val_outputs.append(outputs.softmax(dim=1)[:, 1].cpu())\n",
        "\n",
        "#     scheduler.step()\n",
        "#     return torch.cat(val_targets).numpy(), torch.cat(val_outputs).numpy()\n",
        "\n",
        "def train_evaluate(model, train_loader, val_loader, criterion, optimizer, scheduler, device):\n",
        "    scaler = GradScaler()  # Updated from the deprecated version\n",
        "\n",
        "    # Training phase\n",
        "    model.train()\n",
        "    train_loss = 0.0\n",
        "    for images, tabular_data, class_targets in tqdm(train_loader, desc=\"Training\"):\n",
        "        images, tabular_data, class_targets = images.to(device), tabular_data.to(device).float(), class_targets.to(device)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        with autocast():  # Updated to the new autocast syntax\n",
        "            outputs, seg_mask = model(images, tabular_data)  # Pass both images and tabular data\n",
        "            loss = criterion(outputs, seg_mask, class_targets)  # Pass seg_mask to criterion\n",
        "\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.unscale_(optimizer)\n",
        "        torch.nn.utils.clip_grad_value_(model.parameters(), 1.0)\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = train_loss / len(train_loader)  # Calculate average loss for training\n",
        "\n",
        "    # Evaluation phase\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    val_targets, val_outputs = [], []\n",
        "    with torch.no_grad(), autocast():  # Updated to the new autocast syntax\n",
        "        for images, tabular_data, class_targets in tqdm(val_loader, desc=\"Evaluating\"):\n",
        "            images, tabular_data, class_targets = images.to(device), tabular_data.to(device).float(), class_targets.to(device)\n",
        "            outputs, seg_mask = model(images, tabular_data)  # Pass both images and tabular data\n",
        "            loss = criterion(outputs, seg_mask, class_targets)  # Pass seg_mask to criterion\n",
        "            val_loss += loss.item()\n",
        "            val_targets.append(class_targets.cpu())\n",
        "            val_outputs.append(outputs.softmax(dim=1)[:, 1].cpu())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)  # Calculate average loss for validation\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "    return torch.cat(val_targets).numpy(), torch.cat(val_outputs).numpy(), avg_train_loss, avg_val_loss\n",
        "\n",
        "def cross_validation_train(df_train, num_folds, num_epochs, hdf5_file_path, aug_transform, base_transform, device):\n",
        "    # Define the combined loss function for Cross Entropy and Tversky Loss\n",
        "    criterion = CombinedLoss(gamma=0.25).to(device)\n",
        "    best_overall_targets, best_overall_outputs = None, None  # Best results across all folds\n",
        "\n",
        "    for fold in range(num_folds):\n",
        "        print(f\"\\nFold {fold + 1}/{num_folds}\")\n",
        "\n",
        "        # Split data for the current fold\n",
        "        train_df = df_train[df_train['fold'] != fold]\n",
        "        val_df = df_train[df_train['fold'] == fold]\n",
        "\n",
        "        # Create datasets and data loaders\n",
        "        train_dataset = ISICDataset(hdf5_file_path, train_df['isic_id'].values, train_df[feature_cols].values, train_df['target'].values, aug_transform)\n",
        "        val_dataset = ISICDataset(hdf5_file_path, val_df['isic_id'].values, val_df[feature_cols].values, val_df['target'].values, base_transform)\n",
        "\n",
        "        labels = train_dataset.get_labels()\n",
        "        class_weights = torch.tensor(compute_class_weight(class_weight=\"balanced\", classes=np.unique(labels), y=labels))\n",
        "\n",
        "        samples_weights = class_weights[labels]\n",
        "        print(class_weights)\n",
        "        sampler = WeightedRandomSampler(weights=samples_weights, num_samples=len(samples_weights), replacement=True)\n",
        "\n",
        "        train_loader = DataLoader(train_dataset, batch_size=128, shuffle=sampler, num_workers=8, pin_memory=True)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=8, pin_memory=True)\n",
        "\n",
        "        # Initialize model, optimizer, and scheduler once per fold\n",
        "        model = setup_isic_model().to(device)\n",
        "        optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005, weight_decay=1e-6)\n",
        "        # optimizer = torch.optim.SGD(model.parameters(), lr=0.002, momentum=0.9, weight_decay=1e-5)\n",
        "        # Define the optimizer with different learning rates for each parameter group\n",
        "        # optimizer = torch.optim.AdamW([\n",
        "        #     {'params': segmentation_params, 'lr': 0.003},  # Learning rate for segmentation task\n",
        "        #     {'params': classification_params, 'lr': 0.0009}  # Learning rate for classification task\n",
        "        # ], weight_decay=1e-5)\n",
        "        scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=num_epochs)\n",
        "\n",
        "        best_score = float('-inf')  # Initialize the best score to negative infinity\n",
        "        best_model_path = f'model_fold_{fold + 1}_best.pth'  # Path to save the best model for this fold\n",
        "\n",
        "        best_val_targets, best_val_outputs = None, None  # Best targets and outputs for this fold\n",
        "\n",
        "        for epoch in range(num_epochs):\n",
        "            print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "\n",
        "            print(f\"Train: {len(train_dataset)}, Val: {len(val_dataset)}, \"\n",
        "                  f\"Train Pos Ratio: {train_df['target'].mean():.2%}, Val Pos Ratio: {val_df['target'].mean():.2%}\")\n",
        "\n",
        "            # Train and evaluate\n",
        "            val_targets, val_outputs, avg_train_loss, avg_val_loss = train_evaluate(\n",
        "                model, train_loader, val_loader, criterion, optimizer, scheduler, device)\n",
        "\n",
        "            print(f'Epoch {epoch + 1} - Train Loss: {avg_train_loss:.4f}, Val Loss: {avg_val_loss:.4f}')\n",
        "\n",
        "            # Create DataFrames with row_id for scoring\n",
        "            solution_df = pd.DataFrame({'target': val_targets, 'row_id': range(len(val_targets))})\n",
        "            submission_df = pd.DataFrame({'prediction': val_outputs, 'row_id': range(len(val_outputs))})\n",
        "            fold_score = score(solution_df, submission_df, 'row_id')\n",
        "            print(f'Fold {fold + 1}, Epoch {epoch + 1} pAUC Score: {fold_score:.4f}')\n",
        "\n",
        "            # Save the model and best results if this is the best score for this fold\n",
        "            if fold_score > best_score:\n",
        "                best_score = fold_score\n",
        "                best_val_targets = val_targets  # Save the best targets\n",
        "                best_val_outputs = val_outputs  # Save the best outputs\n",
        "                torch.save(model.state_dict(), best_model_path)\n",
        "                print(f\"New best model saved for fold {fold + 1} with pAUC Score: {best_score:.4f}\")\n",
        "\n",
        "        # After all epochs for the current fold, store the best results\n",
        "        if best_val_targets is not None and best_val_outputs is not None:\n",
        "            if best_overall_targets is None and best_overall_outputs is None:\n",
        "                best_overall_targets = best_val_targets\n",
        "                best_overall_outputs = best_val_outputs\n",
        "            else:\n",
        "                best_overall_targets = np.concatenate([best_overall_targets, best_val_targets])\n",
        "                best_overall_outputs = np.concatenate([best_overall_outputs, best_val_outputs])\n",
        "\n",
        "    print(f'\\nBest models saved for each fold.')\n",
        "\n",
        "    # Return the best accumulated targets and outputs for final evaluation\n",
        "    return np.array(best_overall_targets), np.array(best_overall_outputs)\n",
        "\n",
        "\n",
        "# Set up CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Perform cross-validation training and get the accumulated results\n",
        "all_val_targets, all_val_outputs = cross_validation_train(df_train_balanced, num_folds, num_epochs, TRAIN_HDF5_FILE_PATH, aug_transform, base_transform, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XcvfDCa4PggF"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "# files.download('model_fold_1_best.pth')\n",
        "# # files.download('model_fold_2_best.pth')\n",
        "# # files.download('model_fold_3_best.pth')\n",
        "# # files.download('model_fold_4_best.pth')\n",
        "# # files.download('model_fold_5_best.pth')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_fold_1_best.pth /content/drive/MyDrive/Kaggle"
      ],
      "metadata": {
        "id": "4P8lDQfKY0x6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31390237-0336-4322-ef0e-b645e50bf87a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/content/drive/MyDrive/Kaggle': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_fold_2_best.pth /content/drive/MyDrive/Kaggle"
      ],
      "metadata": {
        "id": "jTtGdObIZJ5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_fold_3_best.pth /content/drive/MyDrive/Kaggle"
      ],
      "metadata": {
        "id": "erNLw_qvZKAe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_fold_4_best.pth /content/drive/MyDrive/Kaggle"
      ],
      "metadata": {
        "id": "YuPNWkiLZLwk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp /content/model_fold_5_best.pth /content/drive/MyDrive/Kaggle"
      ],
      "metadata": {
        "id": "sZjmCBSrZL3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPGEf_SqVBfc",
        "outputId": "f98c4d7e-e8a2-42d4-b099-f9ba8485e469"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Final Overall Evaluation:\n",
            "Overall pAUC Score: 0.1691\n",
            "\n",
            "Overall Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "     Class 0       0.96      0.98      0.97      4005\n",
            "     Class 1       0.74      0.63      0.68       393\n",
            "\n",
            "    accuracy                           0.95      4398\n",
            "   macro avg       0.85      0.81      0.83      4398\n",
            "weighted avg       0.94      0.95      0.95      4398\n",
            "\n",
            "\n",
            "Class 1 Metrics:\n",
            "Precision: 0.7433\n",
            "Recall: 0.6336\n",
            "F1-score: 0.6841\n"
          ]
        }
      ],
      "source": [
        "# Final overall evaluation\n",
        "print(\"\\nFinal Overall Evaluation:\")\n",
        "\n",
        "# Calculate the official pAUC score\n",
        "solution_df = pd.DataFrame({'target': all_val_targets, 'row_id': range(len(all_val_targets))})\n",
        "submission_df = pd.DataFrame({'prediction': all_val_outputs, 'row_id': range(len(all_val_outputs))})\n",
        "official_score = score(solution_df, submission_df, 'row_id')\n",
        "print(f'Overall pAUC Score: {official_score:.4f}')\n",
        "\n",
        "# Generate and print classification report\n",
        "binary_predictions = binarize(np.array(all_val_outputs).reshape(-1, 1), threshold=0.5).reshape(-1)\n",
        "report = classification_report(all_val_targets, binary_predictions, target_names=['Class 0', 'Class 1'])\n",
        "print(\"\\nOverall Classification Report:\")\n",
        "print(report)\n",
        "\n",
        "# Print specific metrics for Class 1\n",
        "report_dict = classification_report(all_val_targets, binary_predictions, target_names=['Class 0', 'Class 1'], output_dict=True)\n",
        "print(f\"\\nClass 1 Metrics:\")\n",
        "print(f\"Precision: {report_dict['Class 1']['precision']:.4f}\")\n",
        "print(f\"Recall: {report_dict['Class 1']['recall']:.4f}\")\n",
        "print(f\"F1-score: {report_dict['Class 1']['f1-score']:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Final Overall Evaluation:\n",
        "# Overall pAUC Score: 0.1693\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.96      0.98      0.97      4005\n",
        "#      Class 1       0.74      0.63      0.68       393\n",
        "\n",
        "#     accuracy                           0.95      4398\n",
        "#    macro avg       0.85      0.80      0.83      4398\n",
        "# weighted avg       0.94      0.95      0.95      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.7395\n",
        "# Recall: 0.6285\n",
        "# # F1-score: 0.6795"
      ],
      "metadata": {
        "id": "W-QpujRbNnMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9-pPfW4juxXU"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Final Overall Evaluation:\n",
        "# Overall pAUC Score: 0.1643\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.98      0.92      0.95      4005\n",
        "#      Class 1       0.52      0.85      0.65       393\n",
        "\n",
        "#     accuracy                           0.92      4398\n",
        "#    macro avg       0.75      0.89      0.80      4398\n",
        "# weighted avg       0.94      0.92      0.93      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.5226\n",
        "# Recall: 0.8550\n",
        "# F1-score: 0.6486"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XzX45nYoswEC"
      },
      "outputs": [],
      "source": [
        "# Final Overall Evaluation: 1.5 with tab\n",
        "# Overall pAUC Score: 0.1496\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.99      0.85      0.91      4005\n",
        "#      Class 1       0.37      0.87      0.51       393\n",
        "\n",
        "#     accuracy                           0.85      4398\n",
        "#    macro avg       0.68      0.86      0.71      4398\n",
        "# weighted avg       0.93      0.85      0.88      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.3654\n",
        "# Recall: 0.8702\n",
        "# F1-score: 0.5147"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qmceTWiBlS1m"
      },
      "outputs": [],
      "source": [
        "# Final Overall Evaluation:\n",
        "# Overall pAUC Score: 0.1524 1.25 with tab\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.98      0.90      0.94      4005\n",
        "#      Class 1       0.45      0.83      0.58       393\n",
        "\n",
        "#     accuracy                           0.89      4398\n",
        "#    macro avg       0.71      0.86      0.76      4398\n",
        "# weighted avg       0.93      0.89      0.91      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.4464\n",
        "# Recall: 0.8270\n",
        "# F1-score: 0.5798"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2at2Wr2caZMM"
      },
      "outputs": [],
      "source": [
        "# Final Overall Evaluation: CE 1\n",
        "# Overall pAUC Score: 0.1468\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.98      0.88      0.93      4005\n",
        "#      Class 1       0.41      0.82      0.54       393\n",
        "\n",
        "#     accuracy                           0.88      4398\n",
        "#    macro avg       0.69      0.85      0.74      4398\n",
        "# weighted avg       0.93      0.88      0.89      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.4076\n",
        "# Recall: 0.8193\n",
        "# F1-score: 0.5444"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e3LXMRTPDoS4"
      },
      "outputs": [],
      "source": [
        "# Final Overall Evaluation: CE 1.5\n",
        "# Overall pAUC Score: 0.1481\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.98      0.88      0.93      4005\n",
        "#      Class 1       0.40      0.82      0.53       393\n",
        "\n",
        "#     accuracy                           0.87      4398\n",
        "#    macro avg       0.69      0.85      0.73      4398\n",
        "# weighted avg       0.93      0.87      0.89      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.3973\n",
        "# Recall: 0.8168\n",
        "# F1-score: 0.5346"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mI-i4JuT5N-I"
      },
      "outputs": [],
      "source": [
        "# Final Overall Evaluation: CE:2 1\n",
        "# Overall pAUC Score: 0.1434\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.98      0.84      0.91      4005\n",
        "#      Class 1       0.35      0.87      0.50       393\n",
        "\n",
        "#     accuracy                           0.85      4398\n",
        "#    macro avg       0.67      0.86      0.71      4398\n",
        "# weighted avg       0.93      0.85      0.87      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.3526\n",
        "# Recall: 0.8677\n",
        "# F1-score: 0.5015"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P1SY3js9ym7T"
      },
      "outputs": [],
      "source": [
        "# Final Overall Evaluation:  CE 3:1\n",
        "# Overall pAUC Score: 0.1411\n",
        "\n",
        "# Overall Classification Report:\n",
        "#               precision    recall  f1-score   support\n",
        "\n",
        "#      Class 0       0.99      0.84      0.91      4005\n",
        "#      Class 1       0.35      0.87      0.50       393\n",
        "\n",
        "#     accuracy                           0.84      4398\n",
        "#    macro avg       0.67      0.86      0.70      4398\n",
        "# weighted avg       0.93      0.84      0.87      4398\n",
        "\n",
        "\n",
        "# Class 1 Metrics:\n",
        "# Precision: 0.3518\n",
        "# Recall: 0.8728\n",
        "# F1-score: 0.5015"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03iYvhnD5CVa"
      },
      "outputs": [],
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7nSdVYMpVBfc"
      },
      "source": [
        "# Inference Code\n",
        "* There are some duplicate definitions / includes here to make copying to other notebooks easier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6Ds3AWv2VBfc"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import h5py\n",
        "import timm\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import io\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2\n",
        "\n",
        "epoch_for_preds = num_epochs\n",
        "model_path = \"\"\n",
        "\n",
        "class ISICDataset(Dataset):\n",
        "    def __init__(self, hdf5_file, isic_ids, targets=None, transform=None):\n",
        "        self.hdf5_file = h5py.File(hdf5_file, 'r')  # Keep file open\n",
        "        self.isic_ids = isic_ids\n",
        "        self.targets = targets\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.isic_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_bytes = self.hdf5_file[self.isic_ids[idx]][()]\n",
        "        img = Image.open(io.BytesIO(img_bytes))\n",
        "        img = np.array(img)\n",
        "\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=img)\n",
        "            img = transformed['image']\n",
        "\n",
        "        target = self.targets[idx] if self.targets is not None else torch.tensor(-1)\n",
        "        return img, target\n",
        "\n",
        "    def __del__(self):\n",
        "        self.hdf5_file.close()  # Ensure file is closed when object is destroyed\n",
        "\n",
        "# Define the albumentations transformation\n",
        "base_transform = A.Compose([\n",
        "    A.Resize(224, 224),\n",
        "    A.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "    ToTensorV2(),\n",
        "])\n",
        "\n",
        "def setup_isic_model(backbone='tiny_vit_21m_224.dist_in22k_ft_in1k', num_classes=2, freeze_base_model=False, pretrained=True):\n",
        "    model = ISICModel(backbone=backbone, num_classes=num_classes, pretrained=pretrained, freeze_base_model=freeze_base_model)\n",
        "    return model.to(device)\n",
        "\n",
        "def load_models(folds, device):\n",
        "    models = []\n",
        "    for fold in folds:\n",
        "        model = setup_isic_model().to(device)\n",
        "        model.load_state_dict(torch.load(f'{model_path}model_fold_{fold+1}_best.pth', map_location=device))\n",
        "        model.eval()\n",
        "        models.append(model)\n",
        "    return models\n",
        "\n",
        "@torch.no_grad()  # Apply no_grad to the entire function\n",
        "def ensemble_predict(models, test_loader, device):\n",
        "    all_predictions = []\n",
        "    for inputs, _ in tqdm(test_loader, desc=\"Predicting\"):\n",
        "        inputs = inputs.to(device)\n",
        "        fold_predictions = torch.stack([model(inputs).softmax(dim=1)[:, 1] for model in models])\n",
        "        avg_predictions = fold_predictions.mean(dim=0)\n",
        "        all_predictions.extend(avg_predictions.cpu().numpy())\n",
        "    return all_predictions\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTo4-pw7VBfc"
      },
      "source": [
        "# Generate out-of-fold predictions for Train\n",
        "* Only done if not being submitted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-zPlkm03VBfc"
      },
      "outputs": [],
      "source": [
        "def generate_oof_predictions(df_train, folds, hdf5_file_path, transform):\n",
        "    oof_predictions = np.zeros(len(df_train))\n",
        "    model_filenames = [''] * len(df_train)\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    models = load_models(folds, device)\n",
        "\n",
        "    for fold in folds:\n",
        "        print(f\"Generating predictions for fold {fold + 1}/{num_folds}\")\n",
        "        val_df = df_train[df_train['fold'] == fold].copy()\n",
        "        val_dataset = ISICDataset(hdf5_file_path, val_df['isic_id'].values, val_df['target'].values, transform)\n",
        "        val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "        fold_predictions = ensemble_predict([models[fold]], val_loader, device)\n",
        "\n",
        "        oof_predictions[val_df.index] = fold_predictions\n",
        "        model_filename = f'model_fold_{fold+1}_best.pth'\n",
        "        for idx in val_df.index:\n",
        "            model_filenames[idx] = model_filename\n",
        "\n",
        "    return oof_predictions, model_filenames\n",
        "\n",
        "\n",
        "if not scoring:\n",
        "    # Set up CUDA if available\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    # Define the number of folds\n",
        "    folds = [0, 1, 2, 3, 4]\n",
        "\n",
        "    # Generate out-of-fold predictions\n",
        "    oof_predictions, model_filenames = generate_oof_predictions(df_train, folds, TRAIN_HDF5_FILE_PATH, base_transform)\n",
        "\n",
        "    # Create DataFrame for OOF predictions\n",
        "    oof_df = pd.DataFrame({\n",
        "        'isic_id': df_train['isic_id'],\n",
        "        'target': df_train['target'],\n",
        "        'fold': df_train['fold'],\n",
        "        'oof_prediction': oof_predictions,\n",
        "        'model_filename': model_filenames\n",
        "    })\n",
        "\n",
        "    # Save OOF predictions to CSV\n",
        "    oof_df.to_csv('oof_predictions.csv', index=False)\n",
        "    print(\"Out-of-fold predictions saved to oof_predictions.csv\")\n",
        "    print(oof_df.head())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTrWlA1wVBfc"
      },
      "source": [
        "# Predict for test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rMS026cpVBfd"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\"/kaggle/input/isic-2024-challenge/test-metadata.csv\")\n",
        "TEST_HDF5_FILE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
        "\n",
        "# Set up CUDA if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# folds to use for pred\n",
        "folds = [0, 1, 2, 3, 4, 5]\n",
        "\n",
        "models = load_models(folds, device)\n",
        "\n",
        "# Prepare your test dataset\n",
        "test_dataset = ISICDataset(\n",
        "    hdf5_file=TEST_HDF5_FILE_PATH,\n",
        "    isic_ids=df_test['isic_id'].values,\n",
        "    transform=base_transform,\n",
        ")\n",
        "\n",
        "# Create test data loader\n",
        "test_loader = DataLoader(test_dataset, batch_size=512, shuffle=False, num_workers=4, pin_memory=True)\n",
        "\n",
        "# Run predictions\n",
        "predictions = ensemble_predict(models, test_loader, device)\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission_df = pd.DataFrame({\n",
        "    'isic_id': df_test['isic_id'],\n",
        "    'target': predictions\n",
        "})\n",
        "\n",
        "# Save predictions to CSV\n",
        "submission_df.to_csv('submission.csv', index=False)\n",
        "print(\"Predictions saved to submission.csv\")\n",
        "print(submission_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uiV99f6yVBfd"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "databundleVersionId": 9094797,
          "sourceId": 63056,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30733,
      "isGpuEnabled": true,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}